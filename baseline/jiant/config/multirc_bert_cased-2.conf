// Config settings used for SuperGLUE BERT baseline experiments.

// This imports the defaults, which can be overridden below.
include "defaults.conf"
exp_name = "bert_uncased_multirc_PT"
run_name = "run0"
target_tasks = "multirc"

// Data and preprocessing settings
max_seq_len = 256 // Mainly needed for MultiRC, to avoid over-truncating
                  // But not 512 as that is really hard to fit in memory.

// Model settings
input_module = bert-base-cased
transformers_output_mode = "top"
pair_attn = 0 // shouldn't be needed but JIC
s2s = {
    attention = none
}
sent_enc = "none"
sep_embs_for_skip = 1
classifier = log_reg // following BERT paper
transfer_paradigm = finetune // finetune entire BERT model

// Training settings
dropout = 0.1 // following BERT paper
optimizer = bert_adam
batch_size = 32
max_epochs = 10
lr = .000005
min_lr = .000001
lr_patience = 4
patience = 5
max_vals = 10
val_interval=1

// Control-flow stuff
do_pretrain = 1
do_target_task_training = 1
do_full_eval = 1
write_preds = "val,test"
write_strict_glue_format = 1


target_train_val_interval = 1  // Comparable to val_interval, used during
                                 // do_target_task_training. Can be set separately per task.
target_train_max_vals = 100  // Comparable to max_vals, used during do_target_task_training.
                              // Can be set separately per task.