03/21 05:10:03 PM: Git branch: develop
03/21 05:10:03 PM: Git SHA: ad4f3065b67c62c9b88c43982000c96f59fb7d41
03/21 05:10:04 PM: Parsed args: 
{
  "batch_size": 8,
  "classifier": "log_reg",
  "d_word": 50,
  "do_target_task_training": 0,
  "dropout": 0.1,
  "dropout_embs": 0.1,
  "exp_dir": "/Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/",
  "exp_name": "mutlirc_bert_cased_exp",
  "input_module": "bert-large-cased",
  "load_model": 0,
  "local_log_path": "/Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run8/log.log",
  "lr": 1e-05,
  "max_epochs": 10,
  "max_seq_len": 10,
  "max_vals": 20,
  "max_word_v_size": 1000,
  "optimizer": "bert_adam",
  "pair_attn": 0,
  "pretrain_tasks": "multirc",
  "random_seed": 22,
  "remote_log_name": "mutlirc_bert_cased_exp__mutlirc_bert_cased_run8",
  "run_dir": "/Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run8",
  "run_name": "mutlirc_bert_cased_run8",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "multirc",
  "target_train_max_vals": 10,
  "target_train_val_interval": 10,
  "transfer_paradigm": "finetune",
  "val_interval": 10,
  "write_preds": "val,test",
  "write_strict_glue_format": 1
}
03/21 05:10:04 PM: Saved config to /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run8/params.conf
03/21 05:10:04 PM: Using random seed 22
03/21 05:10:04 PM: Loading tasks...
03/21 05:10:04 PM: Writing pre-preprocessed tasks to /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/
03/21 05:10:04 PM: 	Creating task multirc from scratch.
03/21 05:10:04 PM: 	Task 'multirc': |train|=27243 |val|=4848 |test|=9693
03/21 05:10:04 PM: 	Finished loading tasks: multirc.
03/21 05:10:04 PM: Loading token dictionary from /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/vocab.
03/21 05:10:04 PM: 	Loaded vocab from /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/vocab
03/21 05:10:04 PM: 	Vocab namespace chars: size 100
03/21 05:10:04 PM: 	Vocab namespace bert_cased: size 28998
03/21 05:10:04 PM: 	Vocab namespace tokens: size 1004
03/21 05:10:04 PM: 	Finished building vocab.
03/21 05:10:04 PM: 	Task 'multirc', split 'train': Found preprocessed copy in /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/preproc/multirc__train_data
03/21 05:10:04 PM: 	Task 'multirc', split 'val': Found preprocessed copy in /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/preproc/multirc__val_data
03/21 05:10:04 PM: 	Task 'multirc', split 'test': Found preprocessed copy in /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/preproc/multirc__test_data
03/21 05:10:04 PM: 	Finished indexing tasks
03/21 05:10:04 PM: 	Creating trimmed pretraining-only version of multirc train.
03/21 05:10:04 PM: 	Creating trimmed target-only version of multirc train.
03/21 05:10:04 PM: 	  Training on multirc
03/21 05:10:04 PM: 	  Evaluating on multirc
03/21 05:10:04 PM: 	Finished loading tasks in 0.062s
03/21 05:10:04 PM: 	 Tasks: ['multirc']
03/21 05:10:04 PM: Building model...
03/21 05:10:04 PM: Using BERT model (bert-large-cased).
03/21 05:10:04 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-config.json not found in cache or force_download set to True, downloading to /var/folders/mq/hgvjbtjn4td2k7bkt_nhjd8r0000gn/T/tmpo6o4z6tv
03/21 05:10:04 PM: copying /var/folders/mq/hgvjbtjn4td2k7bkt_nhjd8r0000gn/T/tmpo6o4z6tv to cache at /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/transformers_cache/90deb4d9dd705272dc4b3db1364d759d551d72a9f70a91f60e3a1f5e278b985d.960df871e8c3e87cb781ccdbdd12a3c1e0ad83b173a9754bd183354449046e38
03/21 05:10:04 PM: creating metadata file for /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/transformers_cache/90deb4d9dd705272dc4b3db1364d759d551d72a9f70a91f60e3a1f5e278b985d.960df871e8c3e87cb781ccdbdd12a3c1e0ad83b173a9754bd183354449046e38
03/21 05:10:04 PM: removing temp file /var/folders/mq/hgvjbtjn4td2k7bkt_nhjd8r0000gn/T/tmpo6o4z6tv
03/21 05:10:04 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-config.json from cache at /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/transformers_cache/90deb4d9dd705272dc4b3db1364d759d551d72a9f70a91f60e3a1f5e278b985d.960df871e8c3e87cb781ccdbdd12a3c1e0ad83b173a9754bd183354449046e38
03/21 05:10:04 PM: Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

03/21 05:10:04 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-pytorch_model.bin not found in cache or force_download set to True, downloading to /var/folders/mq/hgvjbtjn4td2k7bkt_nhjd8r0000gn/T/tmpibsnuhlc
03/21 05:11:09 PM: copying /var/folders/mq/hgvjbtjn4td2k7bkt_nhjd8r0000gn/T/tmpibsnuhlc to cache at /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/transformers_cache/56c451878be53ca1e310764d1e8312301f3d921378919467947ddd53fef6ba2b.b5f1c2070e0a0c189ca3b08270b0cb5bd0635b7319e74e93bd0dc26689953c27
03/21 05:11:10 PM: creating metadata file for /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/transformers_cache/56c451878be53ca1e310764d1e8312301f3d921378919467947ddd53fef6ba2b.b5f1c2070e0a0c189ca3b08270b0cb5bd0635b7319e74e93bd0dc26689953c27
03/21 05:11:10 PM: removing temp file /var/folders/mq/hgvjbtjn4td2k7bkt_nhjd8r0000gn/T/tmpibsnuhlc
03/21 05:11:10 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-pytorch_model.bin from cache at /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/transformers_cache/56c451878be53ca1e310764d1e8312301f3d921378919467947ddd53fef6ba2b.b5f1c2070e0a0c189ca3b08270b0cb5bd0635b7319e74e93bd0dc26689953c27
03/21 05:11:16 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt not found in cache or force_download set to True, downloading to /var/folders/mq/hgvjbtjn4td2k7bkt_nhjd8r0000gn/T/tmpv4i3710b
03/21 05:11:16 PM: copying /var/folders/mq/hgvjbtjn4td2k7bkt_nhjd8r0000gn/T/tmpv4i3710b to cache at /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/transformers_cache/cee054f6aafe5e2cf816d2228704e326446785f940f5451a5b26033516a4ac3d.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
03/21 05:11:16 PM: creating metadata file for /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/transformers_cache/cee054f6aafe5e2cf816d2228704e326446785f940f5451a5b26033516a4ac3d.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
03/21 05:11:16 PM: removing temp file /var/folders/mq/hgvjbtjn4td2k7bkt_nhjd8r0000gn/T/tmpv4i3710b
03/21 05:11:16 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt from cache at /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/transformers_cache/cee054f6aafe5e2cf816d2228704e326446785f940f5451a5b26033516a4ac3d.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
03/21 05:11:16 PM: Initializing parameters
03/21 05:11:16 PM: Done initializing parameters; the following parameters are using their default initialization from their code
03/21 05:11:16 PM:    _text_field_embedder.model.embeddings.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.embeddings.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.embeddings.position_embeddings.weight
03/21 05:11:16 PM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
03/21 05:11:16 PM:    _text_field_embedder.model.embeddings.word_embeddings.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.12.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.12.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.12.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.12.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.12.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.12.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.12.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.12.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.12.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.12.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.12.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.12.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.12.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.12.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.12.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.12.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.13.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.13.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.13.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.13.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.13.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.13.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.13.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.13.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.13.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.13.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.13.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.13.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.13.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.13.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.13.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.13.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.14.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.14.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.14.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.14.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.14.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.14.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.14.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.14.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.14.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.14.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.14.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.14.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.14.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.14.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.14.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.14.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.15.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.15.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.15.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.15.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.15.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.15.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.15.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.15.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.15.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.15.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.15.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.15.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.15.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.15.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.15.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.15.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.16.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.16.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.16.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.16.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.16.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.16.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.16.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.16.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.16.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.16.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.16.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.16.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.16.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.16.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.16.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.16.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.17.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.17.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.17.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.17.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.17.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.17.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.17.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.17.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.17.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.17.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.17.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.17.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.17.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.17.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.17.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.17.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.18.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.18.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.18.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.18.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.18.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.18.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.18.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.18.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.18.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.18.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.18.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.18.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.18.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.18.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.18.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.18.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.19.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.19.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.19.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.19.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.19.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.19.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.19.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.19.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.19.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.19.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.19.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.19.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.19.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.19.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.19.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.19.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.20.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.20.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.20.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.20.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.20.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.20.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.20.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.20.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.20.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.20.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.20.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.20.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.20.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.20.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.20.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.20.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.21.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.21.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.21.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.21.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.21.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.21.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.21.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.21.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.21.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.21.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.21.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.21.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.21.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.21.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.21.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.21.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.22.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.22.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.22.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.22.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.22.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.22.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.22.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.22.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.22.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.22.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.22.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.22.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.22.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.22.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.22.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.22.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.23.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.23.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.23.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.23.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.23.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.23.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.23.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.23.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.23.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.23.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.23.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.23.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.23.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.23.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.23.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.23.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
03/21 05:11:16 PM:    _text_field_embedder.model.pooler.dense.bias
03/21 05:11:16 PM:    _text_field_embedder.model.pooler.dense.weight
03/21 05:11:16 PM: 	Task 'multirc' params: {
  "cls_type": "log_reg",
  "d_hid": 512,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.2,
  "cls_loss_fn": "softmax",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "multirc"
}
03/21 05:11:16 PM: Model specification:
03/21 05:11:16 PM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 1024, padding_idx=0)
          (position_embeddings): Embedding(512, 1024)
          (token_type_embeddings): Embedding(2, 1024)
          (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (12): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (13): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (14): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (15): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (16): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (17): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (18): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (19): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (20): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (21): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (22): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (23): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=1024, out_features=1024, bias=True)
                  (key): Linear(in_features=1024, out_features=1024, bias=True)
                  (value): Linear(in_features=1024, out_features=1024, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=1024, out_features=1024, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=1024, out_features=4096, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=4096, out_features=1024, bias=True)
                (LayerNorm): LayerNorm(torch.Size([1024]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=1024, out_features=1024, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.1)
  )
  (multirc_mdl): SingleClassifier(
    (pooler): Pooler()
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
03/21 05:11:16 PM: Model parameters:
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Trainable parameter, count 29691904 with torch.Size([28996, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Trainable parameter, count 524288 with torch.Size([512, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Trainable parameter, count 2048 with torch.Size([2, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.12.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.12.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.12.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.12.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.12.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.12.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.12.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.12.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.12.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.12.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.12.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.12.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.12.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.12.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.12.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.12.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.13.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.13.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.13.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.13.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.13.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.13.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.13.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.13.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.13.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.13.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.13.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.13.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.13.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.13.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.13.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.13.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.14.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.14.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.14.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.14.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.14.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.14.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.14.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.14.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.14.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.14.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.14.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.14.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.14.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.14.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.14.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.14.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.15.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.15.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.15.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.15.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.15.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.15.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.15.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.15.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.15.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.15.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.15.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.15.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.15.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.15.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.15.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.15.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.16.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.16.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.16.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.16.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.16.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.16.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.16.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.16.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.16.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.16.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.16.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.16.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.16.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.16.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.16.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.16.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.17.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.17.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.17.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.17.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.17.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.17.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.17.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.17.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.17.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.17.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.17.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.17.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.17.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.17.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.17.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.17.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.18.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.18.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.18.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.18.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.18.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.18.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.18.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.18.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.18.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.18.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.18.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.18.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.18.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.18.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.18.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.18.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.19.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.19.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.19.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.19.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.19.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.19.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.19.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.19.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.19.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.19.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.19.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.19.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.19.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.19.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.19.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.19.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.20.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.20.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.20.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.20.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.20.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.20.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.20.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.20.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.20.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.20.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.20.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.20.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.20.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.20.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.20.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.20.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.21.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.21.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.21.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.21.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.21.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.21.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.21.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.21.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.21.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.21.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.21.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.21.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.21.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.21.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.21.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.21.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.22.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.22.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.22.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.22.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.22.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.22.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.22.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.22.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.22.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.22.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.22.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.22.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.22.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.22.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.22.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.22.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.23.attention.self.query.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.23.attention.self.query.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.23.attention.self.key.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.23.attention.self.key.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.23.attention.self.value.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.23.attention.self.value.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.23.attention.output.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.23.attention.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.23.attention.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.23.attention.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.23.intermediate.dense.weight: Trainable parameter, count 4194304 with torch.Size([4096, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.23.intermediate.dense.bias: Trainable parameter, count 4096 with torch.Size([4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.23.output.dense.weight: Trainable parameter, count 4194304 with torch.Size([1024, 4096])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.23.output.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.23.output.LayerNorm.weight: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.23.output.LayerNorm.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Trainable parameter, count 1048576 with torch.Size([1024, 1024])
03/21 05:11:16 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Trainable parameter, count 1024 with torch.Size([1024])
03/21 05:11:16 PM: 	multirc_mdl.classifier.classifier.weight: Trainable parameter, count 2048 with torch.Size([2, 1024])
03/21 05:11:16 PM: 	multirc_mdl.classifier.classifier.bias: Trainable parameter, count 2 with torch.Size([2])
03/21 05:11:16 PM: Total number of parameters: 333581314 (3.33581e+08)
03/21 05:11:16 PM: Number of trainable parameters: 333581314 (3.33581e+08)
03/21 05:11:16 PM: Finished building model in 72.216s
03/21 05:11:16 PM: Will run the following steps for this experiment:
Training model on tasks: multirc 
Evaluating model on tasks: multirc 

03/21 05:11:16 PM: Training...
03/21 05:11:16 PM: patience = 5
03/21 05:11:16 PM: val_interval = 10
03/21 05:11:16 PM: max_vals = 20
03/21 05:11:16 PM: cuda_device = -1
03/21 05:11:16 PM: grad_norm = 5.0
03/21 05:11:16 PM: grad_clipping = None
03/21 05:11:16 PM: lr_decay = 0.99
03/21 05:11:16 PM: min_lr = 1e-06
03/21 05:11:16 PM: keep_all_checkpoints = 0
03/21 05:11:16 PM: val_data_limit = 5000
03/21 05:11:16 PM: max_epochs = 10
03/21 05:11:16 PM: dec_val_scale = 250
03/21 05:11:16 PM: training_data_fraction = 1
03/21 05:11:16 PM: accumulation_steps = 1
03/21 05:11:16 PM: type = bert_adam
03/21 05:11:16 PM: parameter_groups = None
03/21 05:11:16 PM: Number of trainable parameters: 333581314
03/21 05:11:16 PM: infer_type_and_cast = True
03/21 05:11:16 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
03/21 05:11:16 PM: CURRENTLY DEFINED PARAMETERS: 
03/21 05:11:16 PM: lr = 1e-05
03/21 05:11:16 PM: t_total = 200
03/21 05:11:16 PM: warmup = 0.1
03/21 05:11:16 PM: type = reduce_on_plateau
03/21 05:11:16 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
03/21 05:11:16 PM: CURRENTLY DEFINED PARAMETERS: 
03/21 05:11:16 PM: mode = max
03/21 05:11:16 PM: factor = 0.5
03/21 05:11:16 PM: patience = 1
03/21 05:11:16 PM: threshold = 0.0001
03/21 05:11:16 PM: threshold_mode = abs
03/21 05:11:16 PM: verbose = True
03/21 05:11:16 PM: Starting training without restoring from a checkpoint.
03/21 05:11:16 PM: Training examples per task, before any subsampling: {'multirc': 27243}
03/21 05:11:16 PM: Beginning training with stopping criteria based on metric: multirc_avg
03/21 05:11:31 PM: Update 2: task multirc, steps since last val 2 (total steps = 2): ans_f1: 0.5455, qst_f1: 0.3750, em: 0.3750, avg: 0.4602, multirc_loss: 0.7655
03/21 05:11:43 PM: Update 4: task multirc, steps since last val 4 (total steps = 4): ans_f1: 0.5366, qst_f1: 0.3441, em: 0.3871, avg: 0.4618, multirc_loss: 0.7517
03/21 05:11:56 PM: Update 6: task multirc, steps since last val 6 (total steps = 6): ans_f1: 0.5085, qst_f1: 0.3121, em: 0.3830, avg: 0.4457, multirc_loss: 0.7482
03/21 05:12:08 PM: Update 8: task multirc, steps since last val 8 (total steps = 8): ans_f1: 0.5063, qst_f1: 0.3122, em: 0.3810, avg: 0.4436, multirc_loss: 0.7425
03/21 05:12:20 PM: Update 10: task multirc, steps since last val 10 (total steps = 10): ans_f1: 0.4835, qst_f1: 0.2778, em: 0.4103, avg: 0.4469, multirc_loss: 0.7293
03/21 05:12:20 PM: ***** Step 10 / Validation 1 *****
03/21 05:12:20 PM: multirc: trained on 10 steps (10 batches) since val, 0.003 epochs
03/21 05:12:20 PM: Validating...
03/21 05:12:30 PM: Evaluate: task multirc, batch 21 (606): ans_f1: 0.3680, qst_f1: 0.2275, em: 0.0256, avg: 0.1968, multirc_loss: 0.7039
03/21 05:12:41 PM: Evaluate: task multirc, batch 41 (606): ans_f1: 0.2771, qst_f1: 0.1646, em: 0.0000, avg: 0.1385, multirc_loss: 0.7118
03/21 05:12:51 PM: Evaluate: task multirc, batch 61 (606): ans_f1: 0.2611, qst_f1: 0.1558, em: 0.0189, avg: 0.1400, multirc_loss: 0.7115
03/21 05:13:01 PM: Evaluate: task multirc, batch 81 (606): ans_f1: 0.2992, qst_f1: 0.1899, em: 0.0148, avg: 0.1570, multirc_loss: 0.7085
03/21 05:13:11 PM: Evaluate: task multirc, batch 101 (606): ans_f1: 0.2765, qst_f1: 0.1719, em: 0.0126, avg: 0.1445, multirc_loss: 0.6999
03/21 05:13:22 PM: Evaluate: task multirc, batch 121 (606): ans_f1: 0.2853, qst_f1: 0.1812, em: 0.0107, avg: 0.1480, multirc_loss: 0.6963
03/21 05:13:32 PM: Evaluate: task multirc, batch 143 (606): ans_f1: 0.2792, qst_f1: 0.1669, em: 0.0136, avg: 0.1464, multirc_loss: 0.6910
03/21 05:13:42 PM: Evaluate: task multirc, batch 164 (606): ans_f1: 0.2583, qst_f1: 0.1509, em: 0.0121, avg: 0.1352, multirc_loss: 0.6888
03/21 05:13:53 PM: Evaluate: task multirc, batch 185 (606): ans_f1: 0.2445, qst_f1: 0.1427, em: 0.0142, avg: 0.1293, multirc_loss: 0.6942
03/21 05:14:03 PM: Evaluate: task multirc, batch 206 (606): ans_f1: 0.2525, qst_f1: 0.1496, em: 0.0187, avg: 0.1356, multirc_loss: 0.6930
03/21 05:14:13 PM: Evaluate: task multirc, batch 227 (606): ans_f1: 0.2419, qst_f1: 0.1411, em: 0.0199, avg: 0.1309, multirc_loss: 0.6906
03/21 05:14:24 PM: Evaluate: task multirc, batch 248 (606): ans_f1: 0.2408, qst_f1: 0.1401, em: 0.0180, avg: 0.1294, multirc_loss: 0.6895
03/21 05:14:34 PM: Evaluate: task multirc, batch 269 (606): ans_f1: 0.2404, qst_f1: 0.1351, em: 0.0164, avg: 0.1284, multirc_loss: 0.6926
03/21 05:14:44 PM: Evaluate: task multirc, batch 290 (606): ans_f1: 0.2519, qst_f1: 0.1406, em: 0.0154, avg: 0.1337, multirc_loss: 0.6929
03/21 05:14:55 PM: Evaluate: task multirc, batch 311 (606): ans_f1: 0.2513, qst_f1: 0.1416, em: 0.0164, avg: 0.1339, multirc_loss: 0.6929
03/21 05:15:05 PM: Evaluate: task multirc, batch 332 (606): ans_f1: 0.2508, qst_f1: 0.1394, em: 0.0172, avg: 0.1340, multirc_loss: 0.6940
03/21 05:15:16 PM: Evaluate: task multirc, batch 352 (606): ans_f1: 0.2473, qst_f1: 0.1373, em: 0.0145, avg: 0.1309, multirc_loss: 0.6928
03/21 05:15:26 PM: Evaluate: task multirc, batch 372 (606): ans_f1: 0.2410, qst_f1: 0.1341, em: 0.0138, avg: 0.1274, multirc_loss: 0.6915
03/21 05:15:36 PM: Evaluate: task multirc, batch 393 (606): ans_f1: 0.2480, qst_f1: 0.1385, em: 0.0162, avg: 0.1321, multirc_loss: 0.6918
03/21 05:15:47 PM: Evaluate: task multirc, batch 415 (606): ans_f1: 0.2448, qst_f1: 0.1359, em: 0.0136, avg: 0.1292, multirc_loss: 0.6952
03/21 05:15:57 PM: Evaluate: task multirc, batch 436 (606): ans_f1: 0.2368, qst_f1: 0.1285, em: 0.0128, avg: 0.1248, multirc_loss: 0.6959
03/21 05:16:08 PM: Evaluate: task multirc, batch 457 (606): ans_f1: 0.2307, qst_f1: 0.1261, em: 0.0122, avg: 0.1215, multirc_loss: 0.6967
03/21 05:16:19 PM: Evaluate: task multirc, batch 479 (606): ans_f1: 0.2237, qst_f1: 0.1204, em: 0.0130, avg: 0.1183, multirc_loss: 0.6966
03/21 05:16:29 PM: Evaluate: task multirc, batch 500 (606): ans_f1: 0.2177, qst_f1: 0.1171, em: 0.0125, avg: 0.1151, multirc_loss: 0.6962
03/21 05:16:40 PM: Evaluate: task multirc, batch 521 (606): ans_f1: 0.2158, qst_f1: 0.1168, em: 0.0133, avg: 0.1146, multirc_loss: 0.6956
03/21 05:16:50 PM: Evaluate: task multirc, batch 542 (606): ans_f1: 0.2126, qst_f1: 0.1148, em: 0.0139, avg: 0.1132, multirc_loss: 0.6948
03/21 05:17:01 PM: Evaluate: task multirc, batch 563 (606): ans_f1: 0.2115, qst_f1: 0.1137, em: 0.0135, avg: 0.1125, multirc_loss: 0.6940
03/21 05:17:11 PM: Evaluate: task multirc, batch 584 (606): ans_f1: 0.2078, qst_f1: 0.1111, em: 0.0131, avg: 0.1104, multirc_loss: 0.6931
03/21 05:17:22 PM: Evaluate: task multirc, batch 605 (606): ans_f1: 0.2129, qst_f1: 0.1141, em: 0.0137, avg: 0.1133, multirc_loss: 0.6940
03/21 05:17:23 PM: Best result seen so far for multirc.
03/21 05:17:23 PM: Best result seen so far for micro.
03/21 05:17:23 PM: Best result seen so far for macro.
03/21 05:17:23 PM: Updating LR scheduler:
03/21 05:17:23 PM: 	Best result seen so far for macro_avg: 0.113
03/21 05:17:23 PM: 	# validation passes without improvement: 0
03/21 05:17:23 PM: multirc_loss: training: 0.729260 validation: 0.694097
03/21 05:17:23 PM: macro_avg: validation: 0.113050
03/21 05:17:23 PM: micro_avg: validation: 0.113050
03/21 05:17:23 PM: multirc_ans_f1: training: 0.483516 validation: 0.212459
03/21 05:17:23 PM: multirc_qst_f1: training: 0.277778 validation: 0.113861
03/21 05:17:23 PM: multirc_em: training: 0.410256 validation: 0.013641
03/21 05:17:23 PM: multirc_avg: training: 0.446886 validation: 0.113050
03/21 05:17:23 PM: Global learning rate: 1e-05
03/21 05:17:23 PM: Saving checkpoints to: /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run8
03/21 05:17:32 PM: Update 11: task multirc, steps since last val 1 (total steps = 11): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.7500, avg: 0.3750, multirc_loss: 0.6430
03/21 05:17:45 PM: Update 13: task multirc, steps since last val 3 (total steps = 13): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.7083, avg: 0.3542, multirc_loss: 0.6810
03/21 05:17:58 PM: Update 15: task multirc, steps since last val 5 (total steps = 15): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.7297, avg: 0.3649, multirc_loss: 0.6255
03/21 05:18:12 PM: Update 17: task multirc, steps since last val 7 (total steps = 17): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.6415, avg: 0.3208, multirc_loss: 0.7486
03/21 05:18:25 PM: Update 19: task multirc, steps since last val 9 (total steps = 19): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.6377, avg: 0.3188, multirc_loss: 0.7568
03/21 05:18:32 PM: ***** Step 20 / Validation 2 *****
03/21 05:18:32 PM: multirc: trained on 10 steps (10 batches) since val, 0.003 epochs
03/21 05:18:32 PM: Validating...
03/21 05:18:36 PM: Evaluate: task multirc, batch 5 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7023
03/21 05:18:46 PM: Evaluate: task multirc, batch 21 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0256, avg: 0.0128, multirc_loss: 0.7258
03/21 05:18:56 PM: Evaluate: task multirc, batch 40 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7268
03/21 05:19:07 PM: Evaluate: task multirc, batch 57 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7551
03/21 05:19:18 PM: Evaluate: task multirc, batch 74 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0079, avg: 0.0039, multirc_loss: 0.7346
03/21 05:19:28 PM: Evaluate: task multirc, batch 94 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7247
03/21 05:19:38 PM: Evaluate: task multirc, batch 114 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7218
03/21 05:19:48 PM: Evaluate: task multirc, batch 134 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7128
03/21 05:19:59 PM: Evaluate: task multirc, batch 155 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7062
03/21 05:20:09 PM: Evaluate: task multirc, batch 175 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7047
03/21 05:20:20 PM: Evaluate: task multirc, batch 195 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0033, avg: 0.0017, multirc_loss: 0.7055
03/21 05:20:30 PM: Evaluate: task multirc, batch 211 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0091, avg: 0.0046, multirc_loss: 0.6985
03/21 05:20:41 PM: Evaluate: task multirc, batch 227 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0057, avg: 0.0028, multirc_loss: 0.6947
03/21 05:20:51 PM: Evaluate: task multirc, batch 245 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0052, avg: 0.0026, multirc_loss: 0.6932
03/21 05:21:02 PM: Evaluate: task multirc, batch 266 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0071, avg: 0.0036, multirc_loss: 0.6971
03/21 05:21:12 PM: Evaluate: task multirc, batch 287 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0044, avg: 0.0022, multirc_loss: 0.6984
03/21 05:21:23 PM: Evaluate: task multirc, batch 307 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0042, avg: 0.0021, multirc_loss: 0.6971
03/21 05:21:33 PM: Evaluate: task multirc, batch 328 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0058, avg: 0.0029, multirc_loss: 0.6969
03/21 05:21:44 PM: Evaluate: task multirc, batch 348 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0037, avg: 0.0018, multirc_loss: 0.6970
03/21 05:21:55 PM: Evaluate: task multirc, batch 368 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0035, avg: 0.0017, multirc_loss: 0.7012
03/21 05:22:05 PM: Evaluate: task multirc, batch 388 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0033, avg: 0.0017, multirc_loss: 0.7005
03/21 05:22:16 PM: Evaluate: task multirc, batch 409 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0031, avg: 0.0015, multirc_loss: 0.7059
03/21 05:22:26 PM: Evaluate: task multirc, batch 429 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0029, avg: 0.0015, multirc_loss: 0.7048
03/21 05:22:37 PM: Evaluate: task multirc, batch 449 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0028, avg: 0.0014, multirc_loss: 0.7069
03/21 05:22:48 PM: Evaluate: task multirc, batch 470 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0039, avg: 0.0020, multirc_loss: 0.7045
03/21 05:22:58 PM: Evaluate: task multirc, batch 490 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0038, avg: 0.0019, multirc_loss: 0.7033
03/21 05:23:09 PM: Evaluate: task multirc, batch 510 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0049, avg: 0.0025, multirc_loss: 0.7026
03/21 05:23:19 PM: Evaluate: task multirc, batch 530 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0036, avg: 0.0018, multirc_loss: 0.7033
03/21 05:23:30 PM: Evaluate: task multirc, batch 550 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0046, avg: 0.0023, multirc_loss: 0.7034
03/21 05:23:41 PM: Evaluate: task multirc, batch 571 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0033, avg: 0.0017, multirc_loss: 0.7014
03/21 05:23:52 PM: Evaluate: task multirc, batch 591 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0043, avg: 0.0021, multirc_loss: 0.7007
03/21 05:24:00 PM: Updating LR scheduler:
03/21 05:24:00 PM: 	Best result seen so far for macro_avg: 0.113
03/21 05:24:00 PM: 	# validation passes without improvement: 1
03/21 05:24:00 PM: multirc_loss: training: 0.791821 validation: 0.701314
03/21 05:24:00 PM: macro_avg: validation: 0.002056
03/21 05:24:00 PM: micro_avg: validation: 0.002056
03/21 05:24:00 PM: multirc_ans_f1: training: 0.000000 validation: 0.000963
03/21 05:24:00 PM: multirc_qst_f1: training: 0.000000 validation: 0.000700
03/21 05:24:00 PM: multirc_em: training: 0.592105 validation: 0.003148
03/21 05:24:00 PM: multirc_avg: training: 0.296053 validation: 0.002056
03/21 05:24:00 PM: Global learning rate: 1e-05
03/21 05:24:00 PM: Saving checkpoints to: /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run8
03/21 05:24:09 PM: Update 21: task multirc, steps since last val 1 (total steps = 21): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.4286, avg: 0.2143, multirc_loss: 0.7319
03/21 05:24:22 PM: Update 23: task multirc, steps since last val 3 (total steps = 23): ans_f1: 0.2667, qst_f1: 0.0870, em: 0.5217, avg: 0.3942, multirc_loss: 0.7104
03/21 05:24:36 PM: Update 25: task multirc, steps since last val 5 (total steps = 25): ans_f1: 0.3333, qst_f1: 0.1316, em: 0.5000, avg: 0.4167, multirc_loss: 0.7167
03/21 05:24:49 PM: Update 27: task multirc, steps since last val 7 (total steps = 27): ans_f1: 0.4906, qst_f1: 0.2453, em: 0.5094, avg: 0.5000, multirc_loss: 0.7194
03/21 05:25:02 PM: Update 29: task multirc, steps since last val 9 (total steps = 29): ans_f1: 0.5135, qst_f1: 0.2745, em: 0.4853, avg: 0.4994, multirc_loss: 0.7199
03/21 05:25:09 PM: ***** Step 30 / Validation 3 *****
03/21 05:25:09 PM: multirc: trained on 10 steps (10 batches) since val, 0.003 epochs
03/21 05:25:09 PM: Validating...
03/21 05:25:12 PM: Evaluate: task multirc, batch 8 (606): ans_f1: 0.6087, qst_f1: 0.5984, em: 0.0000, avg: 0.3043, multirc_loss: 0.7380
03/21 05:25:23 PM: Evaluate: task multirc, batch 28 (606): ans_f1: 0.6746, qst_f1: 0.6699, em: 0.0189, avg: 0.3467, multirc_loss: 0.7083
03/21 05:25:33 PM: Evaluate: task multirc, batch 49 (606): ans_f1: 0.6678, qst_f1: 0.6615, em: 0.0227, avg: 0.3453, multirc_loss: 0.7086
03/21 05:25:44 PM: Evaluate: task multirc, batch 69 (606): ans_f1: 0.6667, qst_f1: 0.6564, em: 0.0085, avg: 0.3376, multirc_loss: 0.7047
03/21 05:25:54 PM: Evaluate: task multirc, batch 90 (606): ans_f1: 0.6444, qst_f1: 0.6390, em: 0.0069, avg: 0.3256, multirc_loss: 0.7145
03/21 05:26:04 PM: Evaluate: task multirc, batch 112 (606): ans_f1: 0.6285, qst_f1: 0.6191, em: 0.0058, avg: 0.3172, multirc_loss: 0.7119
03/21 05:26:14 PM: Evaluate: task multirc, batch 134 (606): ans_f1: 0.6180, qst_f1: 0.6049, em: 0.0048, avg: 0.3114, multirc_loss: 0.7222
03/21 05:26:25 PM: Evaluate: task multirc, batch 157 (606): ans_f1: 0.6024, qst_f1: 0.5898, em: 0.0042, avg: 0.3033, multirc_loss: 0.7234
03/21 05:26:35 PM: Evaluate: task multirc, batch 174 (606): ans_f1: 0.6011, qst_f1: 0.5849, em: 0.0038, avg: 0.3025, multirc_loss: 0.7218
03/21 05:26:46 PM: Evaluate: task multirc, batch 189 (606): ans_f1: 0.5994, qst_f1: 0.5752, em: 0.0034, avg: 0.3014, multirc_loss: 0.7198
03/21 05:26:56 PM: Evaluate: task multirc, batch 206 (606): ans_f1: 0.5892, qst_f1: 0.5638, em: 0.0031, avg: 0.2962, multirc_loss: 0.7216
03/21 05:27:07 PM: Evaluate: task multirc, batch 223 (606): ans_f1: 0.5809, qst_f1: 0.5553, em: 0.0029, avg: 0.2919, multirc_loss: 0.7244
03/21 05:27:18 PM: Evaluate: task multirc, batch 242 (606): ans_f1: 0.5763, qst_f1: 0.5500, em: 0.0053, avg: 0.2908, multirc_loss: 0.7243
03/21 05:27:28 PM: Evaluate: task multirc, batch 263 (606): ans_f1: 0.5830, qst_f1: 0.5616, em: 0.0072, avg: 0.2951, multirc_loss: 0.7230
03/21 05:27:39 PM: Evaluate: task multirc, batch 284 (606): ans_f1: 0.5830, qst_f1: 0.5611, em: 0.0044, avg: 0.2937, multirc_loss: 0.7258
03/21 05:27:49 PM: Evaluate: task multirc, batch 302 (606): ans_f1: 0.5805, qst_f1: 0.5582, em: 0.0042, avg: 0.2923, multirc_loss: 0.7263
03/21 05:28:00 PM: Evaluate: task multirc, batch 320 (606): ans_f1: 0.5778, qst_f1: 0.5530, em: 0.0080, avg: 0.2929, multirc_loss: 0.7252
03/21 05:28:11 PM: Evaluate: task multirc, batch 336 (606): ans_f1: 0.5803, qst_f1: 0.5563, em: 0.0076, avg: 0.2939, multirc_loss: 0.7242
03/21 05:28:21 PM: Evaluate: task multirc, batch 352 (606): ans_f1: 0.5809, qst_f1: 0.5579, em: 0.0091, avg: 0.2950, multirc_loss: 0.7225
03/21 05:28:32 PM: Evaluate: task multirc, batch 371 (606): ans_f1: 0.5839, qst_f1: 0.5578, em: 0.0069, avg: 0.2954, multirc_loss: 0.7209
03/21 05:28:43 PM: Evaluate: task multirc, batch 388 (606): ans_f1: 0.5855, qst_f1: 0.5599, em: 0.0083, avg: 0.2969, multirc_loss: 0.7202
03/21 05:28:54 PM: Evaluate: task multirc, batch 403 (606): ans_f1: 0.5901, qst_f1: 0.5665, em: 0.0094, avg: 0.2998, multirc_loss: 0.7187
03/21 05:29:05 PM: Evaluate: task multirc, batch 418 (606): ans_f1: 0.5917, qst_f1: 0.5653, em: 0.0136, avg: 0.3026, multirc_loss: 0.7186
03/21 05:29:15 PM: Evaluate: task multirc, batch 435 (606): ans_f1: 0.5899, qst_f1: 0.5599, em: 0.0157, avg: 0.3028, multirc_loss: 0.7182
03/21 05:29:26 PM: Evaluate: task multirc, batch 452 (606): ans_f1: 0.5936, qst_f1: 0.5638, em: 0.0151, avg: 0.3044, multirc_loss: 0.7176
03/21 05:29:37 PM: Evaluate: task multirc, batch 466 (606): ans_f1: 0.5913, qst_f1: 0.5628, em: 0.0146, avg: 0.3029, multirc_loss: 0.7185
03/21 05:29:48 PM: Evaluate: task multirc, batch 477 (606): ans_f1: 0.5914, qst_f1: 0.5623, em: 0.0156, avg: 0.3035, multirc_loss: 0.7183
03/21 05:29:59 PM: Evaluate: task multirc, batch 492 (606): ans_f1: 0.5903, qst_f1: 0.5623, em: 0.0152, avg: 0.3028, multirc_loss: 0.7186
03/21 05:30:10 PM: Evaluate: task multirc, batch 503 (606): ans_f1: 0.5903, qst_f1: 0.5621, em: 0.0150, avg: 0.3027, multirc_loss: 0.7193
03/21 05:30:21 PM: Evaluate: task multirc, batch 520 (606): ans_f1: 0.5896, qst_f1: 0.5625, em: 0.0157, avg: 0.3027, multirc_loss: 0.7201
03/21 05:30:32 PM: Evaluate: task multirc, batch 535 (606): ans_f1: 0.5895, qst_f1: 0.5620, em: 0.0141, avg: 0.3018, multirc_loss: 0.7198
03/21 05:30:42 PM: Evaluate: task multirc, batch 552 (606): ans_f1: 0.5885, qst_f1: 0.5616, em: 0.0148, avg: 0.3017, multirc_loss: 0.7196
03/21 05:30:53 PM: Evaluate: task multirc, batch 567 (606): ans_f1: 0.5860, qst_f1: 0.5596, em: 0.0135, avg: 0.2997, multirc_loss: 0.7210
03/21 05:31:04 PM: Evaluate: task multirc, batch 583 (606): ans_f1: 0.5851, qst_f1: 0.5596, em: 0.0131, avg: 0.2991, multirc_loss: 0.7222
03/21 05:31:15 PM: Evaluate: task multirc, batch 600 (606): ans_f1: 0.5848, qst_f1: 0.5590, em: 0.0127, avg: 0.2988, multirc_loss: 0.7222
03/21 05:31:19 PM: Best result seen so far for multirc.
03/21 05:31:19 PM: Best result seen so far for micro.
03/21 05:31:19 PM: Best result seen so far for macro.
03/21 05:31:19 PM: Updating LR scheduler:
03/21 05:31:19 PM: 	Best result seen so far for macro_avg: 0.299
03/21 05:31:19 PM: 	# validation passes without improvement: 0
03/21 05:31:19 PM: multirc_loss: training: 0.724782 validation: 0.721759
03/21 05:31:19 PM: macro_avg: validation: 0.299321
03/21 05:31:19 PM: micro_avg: validation: 0.299321
03/21 05:31:19 PM: multirc_ans_f1: training: 0.506024 validation: 0.586051
03/21 05:31:19 PM: multirc_qst_f1: training: 0.262222 validation: 0.560887
03/21 05:31:19 PM: multirc_em: training: 0.466667 validation: 0.012592
03/21 05:31:19 PM: multirc_avg: training: 0.486345 validation: 0.299321
03/21 05:31:19 PM: Global learning rate: 1e-05
03/21 05:31:19 PM: Saving checkpoints to: /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run8
03/21 05:31:32 PM: Update 31: task multirc, steps since last val 1 (total steps = 31): ans_f1: 0.8333, qst_f1: 0.6250, em: 0.7500, avg: 0.7917, multirc_loss: 0.5986
03/21 05:31:45 PM: Update 33: task multirc, steps since last val 3 (total steps = 33): ans_f1: 0.6875, qst_f1: 0.4583, em: 0.5833, avg: 0.6354, multirc_loss: 0.6504
03/21 05:31:59 PM: Update 35: task multirc, steps since last val 5 (total steps = 35): ans_f1: 0.5769, qst_f1: 0.3750, em: 0.4500, avg: 0.5135, multirc_loss: 0.7256
03/21 05:32:14 PM: Update 37: task multirc, steps since last val 7 (total steps = 37): ans_f1: 0.5484, qst_f1: 0.3091, em: 0.4909, avg: 0.5196, multirc_loss: 0.7015
03/21 05:32:28 PM: Update 39: task multirc, steps since last val 9 (total steps = 39): ans_f1: 0.5075, qst_f1: 0.2394, em: 0.5352, avg: 0.5213, multirc_loss: 0.6912
03/21 05:32:35 PM: ***** Step 40 / Validation 4 *****
03/21 05:32:35 PM: multirc: trained on 10 steps (10 batches) since val, 0.003 epochs
03/21 05:32:35 PM: Validating...
03/21 05:32:39 PM: Evaluate: task multirc, batch 8 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7135
03/21 05:32:49 PM: Evaluate: task multirc, batch 27 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7737
03/21 05:32:59 PM: Evaluate: task multirc, batch 48 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7725
03/21 05:33:09 PM: Evaluate: task multirc, batch 69 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7707
03/21 05:33:20 PM: Evaluate: task multirc, batch 89 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7491
03/21 05:33:30 PM: Evaluate: task multirc, batch 110 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7404
03/21 05:33:40 PM: Evaluate: task multirc, batch 131 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7328
03/21 05:33:51 PM: Evaluate: task multirc, batch 151 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7210
03/21 05:34:01 PM: Evaluate: task multirc, batch 167 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0040, avg: 0.0020, multirc_loss: 0.7197
03/21 05:34:11 PM: Evaluate: task multirc, batch 184 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7270
03/21 05:34:22 PM: Evaluate: task multirc, batch 200 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0032, avg: 0.0016, multirc_loss: 0.7257
03/21 05:34:32 PM: Evaluate: task multirc, batch 215 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0060, avg: 0.0030, multirc_loss: 0.7145
03/21 05:34:42 PM: Evaluate: task multirc, batch 232 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0084, avg: 0.0042, multirc_loss: 0.7122
03/21 05:34:53 PM: Evaluate: task multirc, batch 250 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0051, avg: 0.0026, multirc_loss: 0.7118
03/21 05:35:03 PM: Evaluate: task multirc, batch 267 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0047, avg: 0.0024, multirc_loss: 0.7156
03/21 05:35:13 PM: Evaluate: task multirc, batch 287 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0044, avg: 0.0022, multirc_loss: 0.7141
03/21 05:35:24 PM: Evaluate: task multirc, batch 307 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0042, avg: 0.0021, multirc_loss: 0.7106
03/21 05:35:35 PM: Evaluate: task multirc, batch 327 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0039, avg: 0.0019, multirc_loss: 0.7108
03/21 05:35:45 PM: Evaluate: task multirc, batch 344 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0037, avg: 0.0019, multirc_loss: 0.7094
03/21 05:35:55 PM: Evaluate: task multirc, batch 362 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0035, avg: 0.0018, multirc_loss: 0.7148
03/21 05:36:06 PM: Evaluate: task multirc, batch 380 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0034, avg: 0.0017, multirc_loss: 0.7128
03/21 05:36:17 PM: Evaluate: task multirc, batch 398 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0048, avg: 0.0024, multirc_loss: 0.7162
03/21 05:36:27 PM: Evaluate: task multirc, batch 417 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0030, avg: 0.0015, multirc_loss: 0.7201
03/21 05:36:38 PM: Evaluate: task multirc, batch 435 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0029, avg: 0.0014, multirc_loss: 0.7220
03/21 05:36:49 PM: Evaluate: task multirc, batch 454 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0027, avg: 0.0014, multirc_loss: 0.7255
03/21 05:36:59 PM: Evaluate: task multirc, batch 474 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0052, avg: 0.0026, multirc_loss: 0.7232
03/21 05:37:10 PM: Evaluate: task multirc, batch 495 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0050, avg: 0.0025, multirc_loss: 0.7227
03/21 05:37:21 PM: Evaluate: task multirc, batch 516 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0037, avg: 0.0018, multirc_loss: 0.7201
03/21 05:37:31 PM: Evaluate: task multirc, batch 537 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0035, avg: 0.0018, multirc_loss: 0.7209
03/21 05:37:42 PM: Evaluate: task multirc, batch 558 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0034, avg: 0.0017, multirc_loss: 0.7197
03/21 05:37:53 PM: Evaluate: task multirc, batch 579 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0033, avg: 0.0016, multirc_loss: 0.7157
03/21 05:38:03 PM: Evaluate: task multirc, batch 594 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0032, avg: 0.0016, multirc_loss: 0.7157
03/21 05:38:14 PM: Evaluate: task multirc, batch 606 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0031, avg: 0.0016, multirc_loss: 0.7183
03/21 05:38:15 PM: Updating LR scheduler:
03/21 05:38:15 PM: 	Best result seen so far for macro_avg: 0.299
03/21 05:38:15 PM: 	# validation passes without improvement: 1
03/21 05:38:15 PM: multirc_loss: training: 0.692365 validation: 0.718295
03/21 05:38:15 PM: macro_avg: validation: 0.001574
03/21 05:38:15 PM: micro_avg: validation: 0.001574
03/21 05:38:15 PM: multirc_ans_f1: training: 0.478873 validation: 0.000000
03/21 05:38:15 PM: multirc_qst_f1: training: 0.215190 validation: 0.000000
03/21 05:38:15 PM: multirc_em: training: 0.531646 validation: 0.003148
03/21 05:38:15 PM: multirc_avg: training: 0.505259 validation: 0.001574
03/21 05:38:15 PM: Global learning rate: 1e-05
03/21 05:38:15 PM: Saving checkpoints to: /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run8
03/21 05:38:26 PM: Update 41: task multirc, steps since last val 1 (total steps = 41): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.3750, avg: 0.1875, multirc_loss: 0.8281
03/21 05:38:40 PM: Update 43: task multirc, steps since last val 3 (total steps = 43): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.6250, avg: 0.3125, multirc_loss: 0.6484
03/21 05:38:54 PM: Update 45: task multirc, steps since last val 5 (total steps = 45): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.6750, avg: 0.3375, multirc_loss: 0.6232
03/21 05:39:07 PM: Update 47: task multirc, steps since last val 7 (total steps = 47): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.6415, avg: 0.3208, multirc_loss: 0.6347
03/21 05:39:21 PM: Update 49: task multirc, steps since last val 9 (total steps = 49): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.6176, avg: 0.3088, multirc_loss: 0.6488
03/21 05:39:27 PM: ***** Step 50 / Validation 5 *****
03/21 05:39:27 PM: multirc: trained on 10 steps (10 batches) since val, 0.003 epochs
03/21 05:39:27 PM: Validating...
03/21 05:39:31 PM: Evaluate: task multirc, batch 7 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0833, avg: 0.0417, multirc_loss: 0.6840
03/21 05:39:42 PM: Evaluate: task multirc, batch 27 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7460
03/21 05:39:52 PM: Evaluate: task multirc, batch 46 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7467
03/21 05:40:02 PM: Evaluate: task multirc, batch 65 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7537
03/21 05:40:13 PM: Evaluate: task multirc, batch 84 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0072, avg: 0.0036, multirc_loss: 0.7331
03/21 05:40:23 PM: Evaluate: task multirc, batch 103 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7224
03/21 05:40:34 PM: Evaluate: task multirc, batch 122 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7218
03/21 05:40:44 PM: Evaluate: task multirc, batch 141 (606): ans_f1: 0.0040, qst_f1: 0.0031, em: 0.0000, avg: 0.0020, multirc_loss: 0.7100
03/21 05:40:55 PM: Evaluate: task multirc, batch 160 (606): ans_f1: 0.0036, qst_f1: 0.0028, em: 0.0000, avg: 0.0018, multirc_loss: 0.7060
03/21 05:41:05 PM: Evaluate: task multirc, batch 179 (606): ans_f1: 0.0032, qst_f1: 0.0025, em: 0.0000, avg: 0.0016, multirc_loss: 0.7147
03/21 05:41:15 PM: Evaluate: task multirc, batch 197 (606): ans_f1: 0.0029, qst_f1: 0.0022, em: 0.0033, avg: 0.0031, multirc_loss: 0.7170
03/21 05:41:26 PM: Evaluate: task multirc, batch 216 (606): ans_f1: 0.0027, qst_f1: 0.0020, em: 0.0060, avg: 0.0044, multirc_loss: 0.7054
03/21 05:41:36 PM: Evaluate: task multirc, batch 234 (606): ans_f1: 0.0025, qst_f1: 0.0018, em: 0.0082, avg: 0.0054, multirc_loss: 0.7052
03/21 05:41:47 PM: Evaluate: task multirc, batch 253 (606): ans_f1: 0.0024, qst_f1: 0.0017, em: 0.0051, avg: 0.0037, multirc_loss: 0.7034
03/21 05:41:57 PM: Evaluate: task multirc, batch 273 (606): ans_f1: 0.0022, qst_f1: 0.0015, em: 0.0046, avg: 0.0034, multirc_loss: 0.7066
03/21 05:42:08 PM: Evaluate: task multirc, batch 293 (606): ans_f1: 0.0020, qst_f1: 0.0014, em: 0.0043, avg: 0.0032, multirc_loss: 0.7043
03/21 05:42:18 PM: Evaluate: task multirc, batch 313 (606): ans_f1: 0.0019, qst_f1: 0.0014, em: 0.0061, avg: 0.0040, multirc_loss: 0.7001
03/21 05:42:29 PM: Evaluate: task multirc, batch 334 (606): ans_f1: 0.0018, qst_f1: 0.0013, em: 0.0038, avg: 0.0028, multirc_loss: 0.7030
03/21 05:42:39 PM: Evaluate: task multirc, batch 354 (606): ans_f1: 0.0017, qst_f1: 0.0012, em: 0.0036, avg: 0.0026, multirc_loss: 0.7026
03/21 05:42:50 PM: Evaluate: task multirc, batch 374 (606): ans_f1: 0.0016, qst_f1: 0.0011, em: 0.0034, avg: 0.0025, multirc_loss: 0.7018
03/21 05:43:00 PM: Evaluate: task multirc, batch 394 (606): ans_f1: 0.0015, qst_f1: 0.0011, em: 0.0032, avg: 0.0024, multirc_loss: 0.7058
03/21 05:43:11 PM: Evaluate: task multirc, batch 415 (606): ans_f1: 0.0014, qst_f1: 0.0010, em: 0.0030, avg: 0.0022, multirc_loss: 0.7109
03/21 05:43:22 PM: Evaluate: task multirc, batch 435 (606): ans_f1: 0.0013, qst_f1: 0.0010, em: 0.0029, avg: 0.0021, multirc_loss: 0.7125
03/21 05:43:32 PM: Evaluate: task multirc, batch 456 (606): ans_f1: 0.0013, qst_f1: 0.0009, em: 0.0041, avg: 0.0027, multirc_loss: 0.7131
03/21 05:43:43 PM: Evaluate: task multirc, batch 477 (606): ans_f1: 0.0012, qst_f1: 0.0009, em: 0.0052, avg: 0.0032, multirc_loss: 0.7121
03/21 05:43:54 PM: Evaluate: task multirc, batch 498 (606): ans_f1: 0.0012, qst_f1: 0.0008, em: 0.0050, avg: 0.0031, multirc_loss: 0.7112
03/21 05:44:04 PM: Evaluate: task multirc, batch 518 (606): ans_f1: 0.0011, qst_f1: 0.0008, em: 0.0036, avg: 0.0024, multirc_loss: 0.7093
03/21 05:44:15 PM: Evaluate: task multirc, batch 538 (606): ans_f1: 0.0011, qst_f1: 0.0008, em: 0.0035, avg: 0.0023, multirc_loss: 0.7093
03/21 05:44:26 PM: Evaluate: task multirc, batch 558 (606): ans_f1: 0.0010, qst_f1: 0.0008, em: 0.0034, avg: 0.0022, multirc_loss: 0.7083
03/21 05:44:37 PM: Evaluate: task multirc, batch 579 (606): ans_f1: 0.0010, qst_f1: 0.0007, em: 0.0033, avg: 0.0022, multirc_loss: 0.7049
03/21 05:44:47 PM: Evaluate: task multirc, batch 599 (606): ans_f1: 0.0010, qst_f1: 0.0007, em: 0.0032, avg: 0.0021, multirc_loss: 0.7050
03/21 05:44:51 PM: Updating LR scheduler:
03/21 05:44:51 PM: 	Best result seen so far for macro_avg: 0.299
03/21 05:44:51 PM: 	# validation passes without improvement: 0
03/21 05:44:51 PM: multirc_loss: training: 0.646395 validation: 0.706882
03/21 05:44:51 PM: macro_avg: validation: 0.002056
03/21 05:44:51 PM: micro_avg: validation: 0.002056
03/21 05:44:51 PM: multirc_ans_f1: training: 0.000000 validation: 0.000963
03/21 05:44:51 PM: multirc_qst_f1: training: 0.000000 validation: 0.000700
03/21 05:44:51 PM: multirc_em: training: 0.618421 validation: 0.003148
03/21 05:44:51 PM: multirc_avg: training: 0.309211 validation: 0.002056
03/21 05:44:51 PM: Global learning rate: 5e-06
03/21 05:44:51 PM: Saving checkpoints to: /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run8
03/21 05:45:01 PM: Update 51: task multirc, steps since last val 1 (total steps = 51): ans_f1: 0.4000, qst_f1: 0.1250, em: 0.6250, avg: 0.5125, multirc_loss: 0.6463
03/21 05:45:13 PM: Update 53: task multirc, steps since last val 3 (total steps = 53): ans_f1: 0.1538, qst_f1: 0.0417, em: 0.5417, avg: 0.3478, multirc_loss: 0.6795
03/21 05:45:26 PM: Update 55: task multirc, steps since last val 5 (total steps = 55): ans_f1: 0.3478, qst_f1: 0.1053, em: 0.6053, avg: 0.4765, multirc_loss: 0.6348
03/21 05:45:38 PM: Update 57: task multirc, steps since last val 7 (total steps = 57): ans_f1: 0.2581, qst_f1: 0.0755, em: 0.5660, avg: 0.4121, multirc_loss: 0.6590
03/21 05:45:51 PM: Update 59: task multirc, steps since last val 9 (total steps = 59): ans_f1: 0.2000, qst_f1: 0.0580, em: 0.5362, avg: 0.3681, multirc_loss: 0.6670
03/21 05:45:57 PM: ***** Step 60 / Validation 6 *****
03/21 05:45:57 PM: multirc: trained on 10 steps (10 batches) since val, 0.003 epochs
03/21 05:45:57 PM: Validating...
03/21 05:46:01 PM: Evaluate: task multirc, batch 8 (606): ans_f1: 0.3000, qst_f1: 0.1722, em: 0.0000, avg: 0.1500, multirc_loss: 0.6703
03/21 05:46:11 PM: Evaluate: task multirc, batch 30 (606): ans_f1: 0.2395, qst_f1: 0.1282, em: 0.0000, avg: 0.1198, multirc_loss: 0.7111
03/21 05:46:22 PM: Evaluate: task multirc, batch 51 (606): ans_f1: 0.3168, qst_f1: 0.1664, em: 0.0109, avg: 0.1639, multirc_loss: 0.7046
03/21 05:46:32 PM: Evaluate: task multirc, batch 72 (606): ans_f1: 0.2872, qst_f1: 0.1479, em: 0.0082, avg: 0.1477, multirc_loss: 0.7008
03/21 05:46:42 PM: Evaluate: task multirc, batch 92 (606): ans_f1: 0.3095, qst_f1: 0.1634, em: 0.0135, avg: 0.1615, multirc_loss: 0.6978
03/21 05:46:53 PM: Evaluate: task multirc, batch 113 (606): ans_f1: 0.2857, qst_f1: 0.1473, em: 0.0116, avg: 0.1486, multirc_loss: 0.6915
03/21 05:47:03 PM: Evaluate: task multirc, batch 134 (606): ans_f1: 0.3364, qst_f1: 0.1845, em: 0.0096, avg: 0.1730, multirc_loss: 0.6922
03/21 05:47:14 PM: Evaluate: task multirc, batch 156 (606): ans_f1: 0.3298, qst_f1: 0.1831, em: 0.0168, avg: 0.1733, multirc_loss: 0.6875
03/21 05:47:24 PM: Evaluate: task multirc, batch 177 (606): ans_f1: 0.3025, qst_f1: 0.1639, em: 0.0150, avg: 0.1588, multirc_loss: 0.6954
03/21 05:47:34 PM: Evaluate: task multirc, batch 198 (606): ans_f1: 0.2956, qst_f1: 0.1565, em: 0.0229, avg: 0.1593, multirc_loss: 0.6969
03/21 05:47:45 PM: Evaluate: task multirc, batch 219 (606): ans_f1: 0.2907, qst_f1: 0.1486, em: 0.0206, avg: 0.1557, multirc_loss: 0.6912
03/21 05:47:55 PM: Evaluate: task multirc, batch 239 (606): ans_f1: 0.2762, qst_f1: 0.1365, em: 0.0214, avg: 0.1488, multirc_loss: 0.6907
03/21 05:48:06 PM: Evaluate: task multirc, batch 260 (606): ans_f1: 0.2775, qst_f1: 0.1432, em: 0.0266, avg: 0.1521, multirc_loss: 0.6911
03/21 05:48:16 PM: Evaluate: task multirc, batch 280 (606): ans_f1: 0.2976, qst_f1: 0.1571, em: 0.0293, avg: 0.1635, multirc_loss: 0.6915
03/21 05:48:27 PM: Evaluate: task multirc, batch 300 (606): ans_f1: 0.3105, qst_f1: 0.1647, em: 0.0276, avg: 0.1690, multirc_loss: 0.6906
03/21 05:48:37 PM: Evaluate: task multirc, batch 321 (606): ans_f1: 0.2997, qst_f1: 0.1552, em: 0.0258, avg: 0.1628, multirc_loss: 0.6897
03/21 05:48:47 PM: Evaluate: task multirc, batch 342 (606): ans_f1: 0.2959, qst_f1: 0.1541, em: 0.0261, avg: 0.1610, multirc_loss: 0.6889
03/21 05:48:58 PM: Evaluate: task multirc, batch 363 (606): ans_f1: 0.3035, qst_f1: 0.1563, em: 0.0248, avg: 0.1641, multirc_loss: 0.6878
03/21 05:49:09 PM: Evaluate: task multirc, batch 384 (606): ans_f1: 0.2945, qst_f1: 0.1492, em: 0.0235, avg: 0.1590, multirc_loss: 0.6874
03/21 05:49:19 PM: Evaluate: task multirc, batch 405 (606): ans_f1: 0.2896, qst_f1: 0.1440, em: 0.0266, avg: 0.1581, multirc_loss: 0.6886
03/21 05:49:30 PM: Evaluate: task multirc, batch 426 (606): ans_f1: 0.2919, qst_f1: 0.1463, em: 0.0266, avg: 0.1592, multirc_loss: 0.6902
03/21 05:49:41 PM: Evaluate: task multirc, batch 447 (606): ans_f1: 0.2915, qst_f1: 0.1464, em: 0.0250, avg: 0.1583, multirc_loss: 0.6927
03/21 05:49:51 PM: Evaluate: task multirc, batch 469 (606): ans_f1: 0.2947, qst_f1: 0.1513, em: 0.0263, avg: 0.1605, multirc_loss: 0.6921
03/21 05:50:02 PM: Evaluate: task multirc, batch 490 (606): ans_f1: 0.2932, qst_f1: 0.1505, em: 0.0254, avg: 0.1593, multirc_loss: 0.6922
03/21 05:50:12 PM: Evaluate: task multirc, batch 511 (606): ans_f1: 0.2946, qst_f1: 0.1522, em: 0.0247, avg: 0.1596, multirc_loss: 0.6918
03/21 05:50:23 PM: Evaluate: task multirc, batch 532 (606): ans_f1: 0.2944, qst_f1: 0.1524, em: 0.0236, avg: 0.1590, multirc_loss: 0.6913
03/21 05:50:34 PM: Evaluate: task multirc, batch 553 (606): ans_f1: 0.2911, qst_f1: 0.1504, em: 0.0228, avg: 0.1569, multirc_loss: 0.6904
03/21 05:50:44 PM: Evaluate: task multirc, batch 574 (606): ans_f1: 0.2921, qst_f1: 0.1508, em: 0.0233, avg: 0.1577, multirc_loss: 0.6892
03/21 05:50:55 PM: Evaluate: task multirc, batch 596 (606): ans_f1: 0.2901, qst_f1: 0.1481, em: 0.0213, avg: 0.1557, multirc_loss: 0.6890
03/21 05:51:00 PM: Updating LR scheduler:
03/21 05:51:00 PM: 	Best result seen so far for macro_avg: 0.299
03/21 05:51:00 PM: 	# validation passes without improvement: 1
03/21 05:51:00 PM: multirc_loss: training: 0.669584 validation: 0.689895
03/21 05:51:00 PM: macro_avg: validation: 0.153156
03/21 05:51:00 PM: micro_avg: validation: 0.153156
03/21 05:51:00 PM: multirc_ans_f1: training: 0.177778 validation: 0.285325
03/21 05:51:00 PM: multirc_qst_f1: training: 0.052632 validation: 0.145663
03/21 05:51:00 PM: multirc_em: training: 0.513158 validation: 0.020986
03/21 05:51:00 PM: multirc_avg: training: 0.345468 validation: 0.153156
03/21 05:51:00 PM: Global learning rate: 5e-06
03/21 05:51:00 PM: Saving checkpoints to: /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run8
03/21 05:51:10 PM: Update 61: task multirc, steps since last val 1 (total steps = 61): ans_f1: 0.6000, qst_f1: 0.3750, em: 0.5000, avg: 0.5500, multirc_loss: 0.7137
03/21 05:51:22 PM: Update 63: task multirc, steps since last val 3 (total steps = 63): ans_f1: 0.4545, qst_f1: 0.2029, em: 0.4783, avg: 0.4664, multirc_loss: 0.6932
03/21 05:51:35 PM: Update 65: task multirc, steps since last val 5 (total steps = 65): ans_f1: 0.4571, qst_f1: 0.2018, em: 0.5000, avg: 0.4786, multirc_loss: 0.7262
03/21 05:51:47 PM: Update 67: task multirc, steps since last val 7 (total steps = 67): ans_f1: 0.3478, qst_f1: 0.1420, em: 0.4444, avg: 0.3961, multirc_loss: 0.7394
03/21 05:51:59 PM: Update 69: task multirc, steps since last val 9 (total steps = 69): ans_f1: 0.3934, qst_f1: 0.1691, em: 0.4783, avg: 0.4359, multirc_loss: 0.7278
03/21 05:52:06 PM: ***** Step 70 / Validation 7 *****
03/21 05:52:06 PM: multirc: trained on 10 steps (10 batches) since val, 0.003 epochs
03/21 05:52:06 PM: Validating...
03/21 05:52:10 PM: Evaluate: task multirc, batch 6 (606): ans_f1: 0.5965, qst_f1: 0.5499, em: 0.0000, avg: 0.2982, multirc_loss: 0.6921
03/21 05:52:20 PM: Evaluate: task multirc, batch 26 (606): ans_f1: 0.6565, qst_f1: 0.5883, em: 0.0208, avg: 0.3387, multirc_loss: 0.6906
03/21 05:52:30 PM: Evaluate: task multirc, batch 47 (606): ans_f1: 0.5977, qst_f1: 0.4780, em: 0.0357, avg: 0.3167, multirc_loss: 0.6959
03/21 05:52:41 PM: Evaluate: task multirc, batch 66 (606): ans_f1: 0.6203, qst_f1: 0.5018, em: 0.0268, avg: 0.3235, multirc_loss: 0.6941
03/21 05:52:51 PM: Evaluate: task multirc, batch 87 (606): ans_f1: 0.5977, qst_f1: 0.5067, em: 0.0211, avg: 0.3094, multirc_loss: 0.7012
03/21 05:53:01 PM: Evaluate: task multirc, batch 109 (606): ans_f1: 0.5786, qst_f1: 0.4668, em: 0.0179, avg: 0.2982, multirc_loss: 0.6953
03/21 05:53:12 PM: Evaluate: task multirc, batch 130 (606): ans_f1: 0.5783, qst_f1: 0.4821, em: 0.0198, avg: 0.2990, multirc_loss: 0.6989
03/21 05:53:22 PM: Evaluate: task multirc, batch 152 (606): ans_f1: 0.5624, qst_f1: 0.4626, em: 0.0256, avg: 0.2940, multirc_loss: 0.6973
03/21 05:53:32 PM: Evaluate: task multirc, batch 173 (606): ans_f1: 0.5452, qst_f1: 0.4432, em: 0.0268, avg: 0.2860, multirc_loss: 0.6984
03/21 05:53:43 PM: Evaluate: task multirc, batch 194 (606): ans_f1: 0.5260, qst_f1: 0.4049, em: 0.0236, avg: 0.2748, multirc_loss: 0.6995
03/21 05:53:53 PM: Evaluate: task multirc, batch 215 (606): ans_f1: 0.5133, qst_f1: 0.3897, em: 0.0299, avg: 0.2716, multirc_loss: 0.6978
03/21 05:54:04 PM: Evaluate: task multirc, batch 236 (606): ans_f1: 0.5051, qst_f1: 0.3763, em: 0.0271, avg: 0.2661, multirc_loss: 0.6986
03/21 05:54:14 PM: Evaluate: task multirc, batch 258 (606): ans_f1: 0.5165, qst_f1: 0.3943, em: 0.0319, avg: 0.2742, multirc_loss: 0.6978
03/21 05:54:25 PM: Evaluate: task multirc, batch 279 (606): ans_f1: 0.5189, qst_f1: 0.4010, em: 0.0295, avg: 0.2742, multirc_loss: 0.6991
03/21 05:54:35 PM: Evaluate: task multirc, batch 300 (606): ans_f1: 0.5204, qst_f1: 0.4029, em: 0.0276, avg: 0.2740, multirc_loss: 0.6991
03/21 05:54:46 PM: Evaluate: task multirc, batch 322 (606): ans_f1: 0.5150, qst_f1: 0.3893, em: 0.0258, avg: 0.2704, multirc_loss: 0.6982
03/21 05:54:56 PM: Evaluate: task multirc, batch 343 (606): ans_f1: 0.5122, qst_f1: 0.3866, em: 0.0298, avg: 0.2710, multirc_loss: 0.6967
03/21 05:55:07 PM: Evaluate: task multirc, batch 364 (606): ans_f1: 0.5275, qst_f1: 0.3993, em: 0.0283, avg: 0.2779, multirc_loss: 0.6954
03/21 05:55:17 PM: Evaluate: task multirc, batch 385 (606): ans_f1: 0.5185, qst_f1: 0.3851, em: 0.0268, avg: 0.2726, multirc_loss: 0.6953
03/21 05:55:28 PM: Evaluate: task multirc, batch 406 (606): ans_f1: 0.5209, qst_f1: 0.3847, em: 0.0265, avg: 0.2737, multirc_loss: 0.6949
03/21 05:55:38 PM: Evaluate: task multirc, batch 427 (606): ans_f1: 0.5155, qst_f1: 0.3748, em: 0.0265, avg: 0.2710, multirc_loss: 0.6959
03/21 05:55:49 PM: Evaluate: task multirc, batch 448 (606): ans_f1: 0.5201, qst_f1: 0.3756, em: 0.0250, avg: 0.2725, multirc_loss: 0.6966
03/21 05:55:59 PM: Evaluate: task multirc, batch 470 (606): ans_f1: 0.5185, qst_f1: 0.3800, em: 0.0289, avg: 0.2737, multirc_loss: 0.6968
03/21 05:56:10 PM: Evaluate: task multirc, batch 491 (606): ans_f1: 0.5160, qst_f1: 0.3804, em: 0.0292, avg: 0.2726, multirc_loss: 0.6972
03/21 05:56:20 PM: Evaluate: task multirc, batch 512 (606): ans_f1: 0.5179, qst_f1: 0.3838, em: 0.0271, avg: 0.2725, multirc_loss: 0.6983
03/21 05:56:31 PM: Evaluate: task multirc, batch 533 (606): ans_f1: 0.5231, qst_f1: 0.3929, em: 0.0259, avg: 0.2745, multirc_loss: 0.6982
03/21 05:56:43 PM: Evaluate: task multirc, batch 550 (606): ans_f1: 0.5259, qst_f1: 0.3957, em: 0.0251, avg: 0.2755, multirc_loss: 0.6975
03/21 05:56:53 PM: Evaluate: task multirc, batch 569 (606): ans_f1: 0.5241, qst_f1: 0.3951, em: 0.0246, avg: 0.2743, multirc_loss: 0.6977
03/21 05:57:04 PM: Evaluate: task multirc, batch 589 (606): ans_f1: 0.5260, qst_f1: 0.3983, em: 0.0237, avg: 0.2749, multirc_loss: 0.6977
03/21 05:57:13 PM: Updating LR scheduler:
03/21 05:57:13 PM: 	Best result seen so far for macro_avg: 0.299
03/21 05:57:13 PM: 	# validation passes without improvement: 0
03/21 05:57:13 PM: multirc_loss: training: 0.724983 validation: 0.697782
03/21 05:57:13 PM: macro_avg: validation: 0.273782
03/21 05:57:13 PM: micro_avg: validation: 0.273782
03/21 05:57:13 PM: multirc_ans_f1: training: 0.388060 validation: 0.524478
03/21 05:57:13 PM: multirc_qst_f1: training: 0.164502 validation: 0.398026
03/21 05:57:13 PM: multirc_em: training: 0.480519 validation: 0.023085
03/21 05:57:13 PM: multirc_avg: training: 0.434290 validation: 0.273782
03/21 05:57:13 PM: Global learning rate: 2.5e-06
03/21 05:57:13 PM: Saving checkpoints to: /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run8
03/21 05:57:24 PM: Update 71: task multirc, steps since last val 1 (total steps = 71): ans_f1: 0.7500, qst_f1: 0.3750, em: 0.7500, avg: 0.7500, multirc_loss: 0.6277
03/21 05:57:37 PM: Update 73: task multirc, steps since last val 3 (total steps = 73): ans_f1: 0.6400, qst_f1: 0.3333, em: 0.6250, avg: 0.6325, multirc_loss: 0.6878
03/21 05:57:51 PM: Update 75: task multirc, steps since last val 5 (total steps = 75): ans_f1: 0.5854, qst_f1: 0.3077, em: 0.5641, avg: 0.5747, multirc_loss: 0.7042
03/21 05:58:04 PM: Update 77: task multirc, steps since last val 7 (total steps = 77): ans_f1: 0.5818, qst_f1: 0.2963, em: 0.5926, avg: 0.5872, multirc_loss: 0.6926
03/21 05:58:18 PM: Update 79: task multirc, steps since last val 9 (total steps = 79): ans_f1: 0.5833, qst_f1: 0.3000, em: 0.5857, avg: 0.5845, multirc_loss: 0.6883
03/21 05:58:24 PM: ***** Step 80 / Validation 8 *****
03/21 05:58:24 PM: multirc: trained on 10 steps (10 batches) since val, 0.003 epochs
03/21 05:58:24 PM: Validating...
03/21 05:58:28 PM: Evaluate: task multirc, batch 7 (606): ans_f1: 0.4348, qst_f1: 0.2610, em: 0.0000, avg: 0.2174, multirc_loss: 0.6756
03/21 05:58:38 PM: Evaluate: task multirc, batch 27 (606): ans_f1: 0.4747, qst_f1: 0.3026, em: 0.0000, avg: 0.2374, multirc_loss: 0.6894
03/21 05:58:49 PM: Evaluate: task multirc, batch 47 (606): ans_f1: 0.4651, qst_f1: 0.2908, em: 0.0238, avg: 0.2445, multirc_loss: 0.6944
03/21 05:58:59 PM: Evaluate: task multirc, batch 66 (606): ans_f1: 0.4908, qst_f1: 0.3242, em: 0.0268, avg: 0.2588, multirc_loss: 0.6909
03/21 05:59:09 PM: Evaluate: task multirc, batch 86 (606): ans_f1: 0.4899, qst_f1: 0.3305, em: 0.0284, avg: 0.2591, multirc_loss: 0.6934
03/21 05:59:20 PM: Evaluate: task multirc, batch 105 (606): ans_f1: 0.4783, qst_f1: 0.3146, em: 0.0368, avg: 0.2575, multirc_loss: 0.6878
03/21 05:59:30 PM: Evaluate: task multirc, batch 124 (606): ans_f1: 0.4940, qst_f1: 0.3387, em: 0.0312, avg: 0.2626, multirc_loss: 0.6895
03/21 05:59:41 PM: Evaluate: task multirc, batch 143 (606): ans_f1: 0.4873, qst_f1: 0.3338, em: 0.0362, avg: 0.2618, multirc_loss: 0.6886
03/21 05:59:51 PM: Evaluate: task multirc, batch 162 (606): ans_f1: 0.4673, qst_f1: 0.3125, em: 0.0369, avg: 0.2521, multirc_loss: 0.6868
03/21 06:00:02 PM: Evaluate: task multirc, batch 181 (606): ans_f1: 0.4463, qst_f1: 0.2906, em: 0.0365, avg: 0.2414, multirc_loss: 0.6901
03/21 06:00:12 PM: Evaluate: task multirc, batch 200 (606): ans_f1: 0.4285, qst_f1: 0.2639, em: 0.0387, avg: 0.2336, multirc_loss: 0.6910
03/21 06:00:23 PM: Evaluate: task multirc, batch 219 (606): ans_f1: 0.4270, qst_f1: 0.2678, em: 0.0442, avg: 0.2356, multirc_loss: 0.6888
03/21 06:00:33 PM: Evaluate: task multirc, batch 238 (606): ans_f1: 0.4101, qst_f1: 0.2481, em: 0.0403, avg: 0.2252, multirc_loss: 0.6889
03/21 06:00:44 PM: Evaluate: task multirc, batch 257 (606): ans_f1: 0.4219, qst_f1: 0.2582, em: 0.0370, avg: 0.2295, multirc_loss: 0.6876
03/21 06:00:55 PM: Evaluate: task multirc, batch 276 (606): ans_f1: 0.4226, qst_f1: 0.2602, em: 0.0365, avg: 0.2296, multirc_loss: 0.6889
03/21 06:01:05 PM: Evaluate: task multirc, batch 295 (606): ans_f1: 0.4339, qst_f1: 0.2661, em: 0.0366, avg: 0.2353, multirc_loss: 0.6886
03/21 06:01:16 PM: Evaluate: task multirc, batch 313 (606): ans_f1: 0.4330, qst_f1: 0.2632, em: 0.0367, avg: 0.2348, multirc_loss: 0.6865
03/21 06:01:26 PM: Evaluate: task multirc, batch 332 (606): ans_f1: 0.4244, qst_f1: 0.2555, em: 0.0363, avg: 0.2304, multirc_loss: 0.6875
03/21 06:01:36 PM: Evaluate: task multirc, batch 350 (606): ans_f1: 0.4175, qst_f1: 0.2496, em: 0.0347, avg: 0.2261, multirc_loss: 0.6859
03/21 06:01:47 PM: Evaluate: task multirc, batch 368 (606): ans_f1: 0.4362, qst_f1: 0.2616, em: 0.0349, avg: 0.2356, multirc_loss: 0.6854
03/21 06:01:58 PM: Evaluate: task multirc, batch 387 (606): ans_f1: 0.4251, qst_f1: 0.2504, em: 0.0332, avg: 0.2292, multirc_loss: 0.6859
03/21 06:02:08 PM: Evaluate: task multirc, batch 406 (606): ans_f1: 0.4282, qst_f1: 0.2511, em: 0.0343, avg: 0.2312, multirc_loss: 0.6861
03/21 06:02:19 PM: Evaluate: task multirc, batch 425 (606): ans_f1: 0.4255, qst_f1: 0.2489, em: 0.0356, avg: 0.2305, multirc_loss: 0.6877
03/21 06:02:30 PM: Evaluate: task multirc, batch 444 (606): ans_f1: 0.4221, qst_f1: 0.2435, em: 0.0336, avg: 0.2279, multirc_loss: 0.6890
03/21 06:02:41 PM: Evaluate: task multirc, batch 463 (606): ans_f1: 0.4234, qst_f1: 0.2487, em: 0.0320, avg: 0.2277, multirc_loss: 0.6889
03/21 06:02:51 PM: Evaluate: task multirc, batch 482 (606): ans_f1: 0.4161, qst_f1: 0.2427, em: 0.0322, avg: 0.2242, multirc_loss: 0.6887
03/21 06:03:02 PM: Evaluate: task multirc, batch 501 (606): ans_f1: 0.4226, qst_f1: 0.2501, em: 0.0326, avg: 0.2276, multirc_loss: 0.6890
03/21 06:03:13 PM: Evaluate: task multirc, batch 520 (606): ans_f1: 0.4267, qst_f1: 0.2568, em: 0.0327, avg: 0.2297, multirc_loss: 0.6893
03/21 06:03:24 PM: Evaluate: task multirc, batch 539 (606): ans_f1: 0.4325, qst_f1: 0.2638, em: 0.0326, avg: 0.2325, multirc_loss: 0.6889
03/21 06:03:35 PM: Evaluate: task multirc, batch 558 (606): ans_f1: 0.4357, qst_f1: 0.2666, em: 0.0329, avg: 0.2343, multirc_loss: 0.6885
03/21 06:03:46 PM: Evaluate: task multirc, batch 577 (606): ans_f1: 0.4341, qst_f1: 0.2648, em: 0.0319, avg: 0.2330, multirc_loss: 0.6879
03/21 06:03:56 PM: Evaluate: task multirc, batch 595 (606): ans_f1: 0.4340, qst_f1: 0.2659, em: 0.0310, avg: 0.2325, multirc_loss: 0.6880
03/21 06:04:03 PM: Updating LR scheduler:
03/21 06:04:03 PM: 	Best result seen so far for macro_avg: 0.299
03/21 06:04:03 PM: 	# validation passes without improvement: 1
03/21 06:04:03 PM: multirc_loss: training: 0.694337 validation: 0.688531
03/21 06:04:03 PM: macro_avg: validation: 0.229767
03/21 06:04:03 PM: micro_avg: validation: 0.229767
03/21 06:04:03 PM: multirc_ans_f1: training: 0.567901 validation: 0.430153
03/21 06:04:03 PM: multirc_qst_f1: training: 0.294372 validation: 0.262984
03/21 06:04:03 PM: multirc_em: training: 0.558442 validation: 0.029381
03/21 06:04:03 PM: multirc_avg: training: 0.563171 validation: 0.229767
03/21 06:04:03 PM: Global learning rate: 2.5e-06
03/21 06:04:03 PM: Saving checkpoints to: /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run8
03/21 06:04:13 PM: Update 81: task multirc, steps since last val 1 (total steps = 81): ans_f1: 0.7500, qst_f1: 0.3750, em: 0.7500, avg: 0.7500, multirc_loss: 0.5705
03/21 06:04:26 PM: Update 83: task multirc, steps since last val 3 (total steps = 83): ans_f1: 0.6250, qst_f1: 0.2083, em: 0.7500, avg: 0.6875, multirc_loss: 0.5967
03/21 06:04:39 PM: Update 85: task multirc, steps since last val 5 (total steps = 85): ans_f1: 0.4800, qst_f1: 0.1538, em: 0.6923, avg: 0.5862, multirc_loss: 0.6219
03/21 06:04:55 PM: Update 87: task multirc, steps since last val 7 (total steps = 87): ans_f1: 0.4103, qst_f1: 0.1283, em: 0.5849, avg: 0.4976, multirc_loss: 0.6434
03/21 06:05:08 PM: Update 89: task multirc, steps since last val 9 (total steps = 89): ans_f1: 0.4364, qst_f1: 0.1588, em: 0.5588, avg: 0.4976, multirc_loss: 0.6667
03/21 06:05:14 PM: ***** Step 90 / Validation 9 *****
03/21 06:05:14 PM: multirc: trained on 10 steps (10 batches) since val, 0.003 epochs
03/21 06:05:14 PM: Validating...
03/21 06:05:18 PM: Evaluate: task multirc, batch 9 (606): ans_f1: 0.4167, qst_f1: 0.2218, em: 0.1333, avg: 0.2750, multirc_loss: 0.6772
03/21 06:05:28 PM: Evaluate: task multirc, batch 29 (606): ans_f1: 0.3543, qst_f1: 0.1933, em: 0.0179, avg: 0.1861, multirc_loss: 0.6975
03/21 06:05:39 PM: Evaluate: task multirc, batch 49 (606): ans_f1: 0.3667, qst_f1: 0.2057, em: 0.0227, avg: 0.1947, multirc_loss: 0.6976
03/21 06:05:50 PM: Evaluate: task multirc, batch 68 (606): ans_f1: 0.3689, qst_f1: 0.2163, em: 0.0256, avg: 0.1973, multirc_loss: 0.6938
03/21 06:06:00 PM: Evaluate: task multirc, batch 86 (606): ans_f1: 0.3970, qst_f1: 0.2320, em: 0.0213, avg: 0.2091, multirc_loss: 0.6940
03/21 06:06:10 PM: Evaluate: task multirc, batch 105 (606): ans_f1: 0.3846, qst_f1: 0.2182, em: 0.0245, avg: 0.2046, multirc_loss: 0.6883
03/21 06:06:20 PM: Evaluate: task multirc, batch 124 (606): ans_f1: 0.4138, qst_f1: 0.2462, em: 0.0208, avg: 0.2173, multirc_loss: 0.6893
03/21 06:06:31 PM: Evaluate: task multirc, batch 144 (606): ans_f1: 0.4091, qst_f1: 0.2428, em: 0.0180, avg: 0.2136, multirc_loss: 0.6863
03/21 06:06:41 PM: Evaluate: task multirc, batch 163 (606): ans_f1: 0.3869, qst_f1: 0.2221, em: 0.0163, avg: 0.2016, multirc_loss: 0.6842
03/21 06:06:51 PM: Evaluate: task multirc, batch 181 (606): ans_f1: 0.3663, qst_f1: 0.2051, em: 0.0146, avg: 0.1905, multirc_loss: 0.6890
03/21 06:07:02 PM: Evaluate: task multirc, batch 200 (606): ans_f1: 0.3508, qst_f1: 0.1883, em: 0.0194, avg: 0.1851, multirc_loss: 0.6902
03/21 06:07:12 PM: Evaluate: task multirc, batch 219 (606): ans_f1: 0.3440, qst_f1: 0.1798, em: 0.0206, avg: 0.1823, multirc_loss: 0.6867
03/21 06:07:23 PM: Evaluate: task multirc, batch 237 (606): ans_f1: 0.3281, qst_f1: 0.1661, em: 0.0189, avg: 0.1735, multirc_loss: 0.6868
03/21 06:07:33 PM: Evaluate: task multirc, batch 256 (606): ans_f1: 0.3462, qst_f1: 0.1807, em: 0.0223, avg: 0.1842, multirc_loss: 0.6854
03/21 06:07:44 PM: Evaluate: task multirc, batch 275 (606): ans_f1: 0.3515, qst_f1: 0.1867, em: 0.0229, avg: 0.1872, multirc_loss: 0.6867
03/21 06:07:54 PM: Evaluate: task multirc, batch 294 (606): ans_f1: 0.3730, qst_f1: 0.1984, em: 0.0216, avg: 0.1973, multirc_loss: 0.6867
03/21 06:08:05 PM: Evaluate: task multirc, batch 313 (606): ans_f1: 0.3683, qst_f1: 0.1923, em: 0.0224, avg: 0.1954, multirc_loss: 0.6844
03/21 06:08:15 PM: Evaluate: task multirc, batch 332 (606): ans_f1: 0.3577, qst_f1: 0.1867, em: 0.0249, avg: 0.1913, multirc_loss: 0.6858
03/21 06:08:26 PM: Evaluate: task multirc, batch 351 (606): ans_f1: 0.3517, qst_f1: 0.1826, em: 0.0237, avg: 0.1877, multirc_loss: 0.6840
03/21 06:08:36 PM: Evaluate: task multirc, batch 369 (606): ans_f1: 0.3659, qst_f1: 0.1892, em: 0.0244, avg: 0.1951, multirc_loss: 0.6837
03/21 06:08:47 PM: Evaluate: task multirc, batch 388 (606): ans_f1: 0.3542, qst_f1: 0.1798, em: 0.0232, avg: 0.1887, multirc_loss: 0.6842
03/21 06:08:58 PM: Evaluate: task multirc, batch 407 (606): ans_f1: 0.3594, qst_f1: 0.1823, em: 0.0249, avg: 0.1922, multirc_loss: 0.6856
03/21 06:09:08 PM: Evaluate: task multirc, batch 426 (606): ans_f1: 0.3558, qst_f1: 0.1797, em: 0.0251, avg: 0.1905, multirc_loss: 0.6864
03/21 06:09:19 PM: Evaluate: task multirc, batch 445 (606): ans_f1: 0.3551, qst_f1: 0.1789, em: 0.0237, avg: 0.1894, multirc_loss: 0.6882
03/21 06:09:30 PM: Evaluate: task multirc, batch 464 (606): ans_f1: 0.3590, qst_f1: 0.1851, em: 0.0252, avg: 0.1921, multirc_loss: 0.6878
03/21 06:09:40 PM: Evaluate: task multirc, batch 483 (606): ans_f1: 0.3519, qst_f1: 0.1806, em: 0.0244, avg: 0.1882, multirc_loss: 0.6874
03/21 06:09:51 PM: Evaluate: task multirc, batch 502 (606): ans_f1: 0.3608, qst_f1: 0.1876, em: 0.0250, avg: 0.1929, multirc_loss: 0.6877
03/21 06:10:02 PM: Evaluate: task multirc, batch 521 (606): ans_f1: 0.3645, qst_f1: 0.1917, em: 0.0242, avg: 0.1944, multirc_loss: 0.6878
03/21 06:10:13 PM: Evaluate: task multirc, batch 540 (606): ans_f1: 0.3698, qst_f1: 0.1975, em: 0.0232, avg: 0.1965, multirc_loss: 0.6874
03/21 06:10:24 PM: Evaluate: task multirc, batch 559 (606): ans_f1: 0.3710, qst_f1: 0.1978, em: 0.0227, avg: 0.1968, multirc_loss: 0.6870
03/21 06:10:34 PM: Evaluate: task multirc, batch 578 (606): ans_f1: 0.3699, qst_f1: 0.1967, em: 0.0231, avg: 0.1965, multirc_loss: 0.6862
03/21 06:10:45 PM: Evaluate: task multirc, batch 597 (606): ans_f1: 0.3688, qst_f1: 0.1966, em: 0.0213, avg: 0.1951, multirc_loss: 0.6864
03/21 06:10:51 PM: Updating LR scheduler:
03/21 06:10:51 PM: 	Best result seen so far for macro_avg: 0.299
03/21 06:10:51 PM: 	# validation passes without improvement: 0
03/21 06:10:51 PM: Ran out of early stopping patience. Stopping training.
03/21 06:10:51 PM: multirc_loss: training: 0.674645 validation: 0.686925
03/21 06:10:51 PM: macro_avg: validation: 0.192609
03/21 06:10:51 PM: micro_avg: validation: 0.192609
03/21 06:10:51 PM: multirc_ans_f1: training: 0.393443 validation: 0.364232
03/21 06:10:51 PM: multirc_qst_f1: training: 0.142105 validation: 0.193878
03/21 06:10:51 PM: multirc_em: training: 0.526316 validation: 0.020986
03/21 06:10:51 PM: multirc_avg: training: 0.459879 validation: 0.192609
03/21 06:10:51 PM: Global learning rate: 1.25e-06
03/21 06:10:51 PM: Saving checkpoints to: /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run8
03/21 06:10:54 PM: Stopped training after 9 validation checks
03/21 06:10:54 PM: Trained multirc for 90 steps or 0.026 epochs
03/21 06:10:54 PM: ***** VALIDATION RESULTS *****
03/21 06:10:54 PM: multirc_avg (for best val pass 3): multirc_loss: 0.72176, macro_avg: 0.29932, micro_avg: 0.29932, multirc_ans_f1: 0.58605, multirc_qst_f1: 0.56089, multirc_em: 0.01259, multirc_avg: 0.29932
03/21 06:10:54 PM: micro_avg (for best val pass 3): multirc_loss: 0.72176, macro_avg: 0.29932, micro_avg: 0.29932, multirc_ans_f1: 0.58605, multirc_qst_f1: 0.56089, multirc_em: 0.01259, multirc_avg: 0.29932
03/21 06:10:54 PM: macro_avg (for best val pass 3): multirc_loss: 0.72176, macro_avg: 0.29932, micro_avg: 0.29932, multirc_ans_f1: 0.58605, multirc_qst_f1: 0.56089, multirc_em: 0.01259, multirc_avg: 0.29932
03/21 06:10:54 PM: Evaluating...
03/21 06:10:56 PM: Loaded model state from /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run8/model_state_pretrain_val_3.best.th
03/21 06:10:56 PM: Evaluating on: multirc, split: val
03/21 06:11:26 PM: 	Task multirc: batch 55
03/21 06:11:57 PM: 	Task multirc: batch 112
03/21 06:12:27 PM: 	Task multirc: batch 170
03/21 06:12:57 PM: 	Task multirc: batch 225
03/21 06:13:28 PM: 	Task multirc: batch 280
03/21 06:13:58 PM: 	Task multirc: batch 336
03/21 06:14:28 PM: 	Task multirc: batch 390
03/21 06:14:58 PM: 	Task multirc: batch 446
03/21 06:15:29 PM: 	Task multirc: batch 502
03/21 06:15:59 PM: 	Task multirc: batch 556
03/21 06:16:27 PM: Task 'multirc': sorting predictions by 'idx'
03/21 06:16:27 PM: Finished evaluating on: multirc
03/21 06:16:27 PM: Task 'multirc': Wrote predictions to /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run8
03/21 06:16:27 PM: Wrote all preds for split 'val' to /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run8
03/21 06:16:27 PM: Evaluating on: multirc, split: test
03/21 06:16:58 PM: 	Task multirc: batch 57
03/21 06:17:28 PM: 	Task multirc: batch 113
03/21 06:17:58 PM: 	Task multirc: batch 171
03/21 06:18:29 PM: 	Task multirc: batch 229
03/21 06:19:00 PM: 	Task multirc: batch 287
03/21 06:19:30 PM: 	Task multirc: batch 344
03/21 06:20:00 PM: 	Task multirc: batch 401
03/21 06:20:31 PM: 	Task multirc: batch 459
03/21 06:21:01 PM: 	Task multirc: batch 516
03/21 06:21:31 PM: 	Task multirc: batch 572
03/21 06:22:01 PM: 	Task multirc: batch 630
03/21 06:22:31 PM: 	Task multirc: batch 687
03/21 06:23:02 PM: 	Task multirc: batch 745
03/21 06:23:32 PM: 	Task multirc: batch 802
03/21 06:24:02 PM: 	Task multirc: batch 860
03/21 06:24:32 PM: 	Task multirc: batch 917
03/21 06:25:03 PM: 	Task multirc: batch 976
03/21 06:25:33 PM: 	Task multirc: batch 1033
03/21 06:26:03 PM: 	Task multirc: batch 1091
03/21 06:26:33 PM: 	Task multirc: batch 1148
03/21 06:27:03 PM: 	Task multirc: batch 1205
03/21 06:27:07 PM: Task 'multirc': sorting predictions by 'idx'
03/21 06:27:07 PM: Finished evaluating on: multirc
03/21 06:27:08 PM: Task 'multirc': Wrote predictions to /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run8
03/21 06:27:08 PM: Wrote all preds for split 'test' to /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run8
03/21 06:27:08 PM: Writing results for split 'val' to /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/results.tsv
03/21 06:27:08 PM: micro_avg: 0.299, macro_avg: 0.299, multirc_ans_f1: 0.586, multirc_qst_f1: 0.561, multirc_em: 0.013, multirc_avg: 0.299
03/21 06:27:08 PM: Done!
