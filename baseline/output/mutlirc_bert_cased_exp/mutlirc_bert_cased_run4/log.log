03/19 07:35:01 PM: Git branch: develop
03/19 07:35:01 PM: Git SHA: dd631065bacec9ae53e4fc1832cfe49321974afb
03/19 07:35:01 PM: Parsed args: 
{
  "batch_size": 8,
  "d_word": 50,
  "do_target_task_training": 0,
  "exp_dir": "/Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/",
  "exp_name": "mutlirc_bert_cased_exp",
  "input_module": "bert-base-cased",
  "load_model": 0,
  "local_log_path": "/Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run4/log.log",
  "lr": 0.005,
  "max_epochs": 10,
  "max_seq_len": 10,
  "max_vals": 20,
  "max_word_v_size": 1000,
  "optimizer": "bert_adam",
  "pair_attn": 0,
  "pretrain_tasks": "multirc",
  "random_seed": 22,
  "remote_log_name": "mutlirc_bert_cased_exp__mutlirc_bert_cased_run4",
  "run_dir": "/Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run4",
  "run_name": "mutlirc_bert_cased_run4",
  "sent_enc": "bow",
  "skip_embs": 0,
  "target_tasks": "multirc",
  "target_train_max_vals": 10,
  "target_train_val_interval": 10,
  "transfer_paradigm": "finetune",
  "val_interval": 50
}
03/19 07:35:01 PM: Saved config to /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run4/params.conf
03/19 07:35:01 PM: Using random seed 22
03/19 07:35:01 PM: Loading tasks...
03/19 07:35:01 PM: Writing pre-preprocessed tasks to /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/
03/19 07:35:01 PM: 	Loaded existing task multirc
03/19 07:35:01 PM: 	Task 'multirc': |train|=27243 |val|=4848 |test|=9693
03/19 07:35:01 PM: 	Finished loading tasks: multirc.
03/19 07:35:01 PM: Loading token dictionary from /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/vocab.
03/19 07:35:01 PM: 	Loaded vocab from /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/vocab
03/19 07:35:01 PM: 	Vocab namespace chars: size 100
03/19 07:35:01 PM: 	Vocab namespace bert_cased: size 28998
03/19 07:35:01 PM: 	Vocab namespace tokens: size 1004
03/19 07:35:01 PM: 	Finished building vocab.
03/19 07:35:01 PM: 	Task 'multirc', split 'train': Found preprocessed copy in /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/preproc/multirc__train_data
03/19 07:35:01 PM: 	Task 'multirc', split 'val': Found preprocessed copy in /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/preproc/multirc__val_data
03/19 07:35:01 PM: 	Task 'multirc', split 'test': Found preprocessed copy in /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/preproc/multirc__test_data
03/19 07:35:01 PM: 	Finished indexing tasks
03/19 07:35:01 PM: 	Creating trimmed pretraining-only version of multirc train.
03/19 07:35:01 PM: 	Creating trimmed target-only version of multirc train.
03/19 07:35:01 PM: 	  Training on multirc
03/19 07:35:01 PM: 	  Evaluating on multirc
03/19 07:35:01 PM: 	Finished loading tasks in 0.055s
03/19 07:35:01 PM: 	 Tasks: ['multirc']
03/19 07:35:01 PM: Building model...
03/19 07:35:01 PM: Using BERT model (bert-base-cased).
03/19 07:35:02 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/transformers_cache/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.3d5adf10d3445c36ce131f4c6416aa62e9b58e1af56b97664773f4858a46286e
03/19 07:35:02 PM: Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

03/19 07:35:02 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/transformers_cache/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
03/19 07:35:04 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/transformers_cache/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
03/19 07:35:04 PM: Initializing parameters
03/19 07:35:04 PM: Done initializing parameters; the following parameters are using their default initialization from their code
03/19 07:35:04 PM:    _text_field_embedder.model.embeddings.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.embeddings.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.embeddings.position_embeddings.weight
03/19 07:35:04 PM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
03/19 07:35:04 PM:    _text_field_embedder.model.embeddings.word_embeddings.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
03/19 07:35:04 PM:    _text_field_embedder.model.pooler.dense.bias
03/19 07:35:04 PM:    _text_field_embedder.model.pooler.dense.weight
03/19 07:35:04 PM: 	Task 'multirc' params: {
  "cls_type": "mlp",
  "d_hid": 512,
  "pool_type": "max",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.2,
  "cls_loss_fn": "softmax",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "multirc"
}
03/19 07:35:04 PM: Model specification:
03/19 07:35:04 PM: MultiTaskModel(
  (sent_encoder): BoWSentEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (multirc_mdl): SingleClassifier(
    (pooler): Pooler()
    (classifier): Classifier(
      (classifier): Sequential(
        (0): Linear(in_features=768, out_features=512, bias=True)
        (1): Tanh()
        (2): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (3): Dropout(p=0.2)
        (4): Linear(in_features=512, out_features=2, bias=True)
      )
    )
  )
)
03/19 07:35:04 PM: Model parameters:
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Trainable parameter, count 22268928 with torch.Size([28996, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Trainable parameter, count 393216 with torch.Size([512, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Trainable parameter, count 1536 with torch.Size([2, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 07:35:04 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 07:35:04 PM: 	multirc_mdl.classifier.classifier.0.weight: Trainable parameter, count 393216 with torch.Size([512, 768])
03/19 07:35:04 PM: 	multirc_mdl.classifier.classifier.0.bias: Trainable parameter, count 512 with torch.Size([512])
03/19 07:35:04 PM: 	multirc_mdl.classifier.classifier.2.weight: Trainable parameter, count 512 with torch.Size([512])
03/19 07:35:04 PM: 	multirc_mdl.classifier.classifier.2.bias: Trainable parameter, count 512 with torch.Size([512])
03/19 07:35:04 PM: 	multirc_mdl.classifier.classifier.4.weight: Trainable parameter, count 1024 with torch.Size([2, 512])
03/19 07:35:04 PM: 	multirc_mdl.classifier.classifier.4.bias: Trainable parameter, count 2 with torch.Size([2])
03/19 07:35:04 PM: Total number of parameters: 108706050 (1.08706e+08)
03/19 07:35:04 PM: Number of trainable parameters: 108706050 (1.08706e+08)
03/19 07:35:04 PM: Finished building model in 2.964s
03/19 07:35:04 PM: Will run the following steps for this experiment:
Training model on tasks: multirc 
Evaluating model on tasks: multirc 

03/19 07:35:04 PM: Training...
03/19 07:35:04 PM: patience = 5
03/19 07:35:04 PM: val_interval = 50
03/19 07:35:04 PM: max_vals = 20
03/19 07:35:04 PM: cuda_device = -1
03/19 07:35:04 PM: grad_norm = 5.0
03/19 07:35:04 PM: grad_clipping = None
03/19 07:35:04 PM: lr_decay = 0.99
03/19 07:35:04 PM: min_lr = 1e-06
03/19 07:35:04 PM: keep_all_checkpoints = 0
03/19 07:35:04 PM: val_data_limit = 5000
03/19 07:35:04 PM: max_epochs = 10
03/19 07:35:04 PM: dec_val_scale = 250
03/19 07:35:04 PM: training_data_fraction = 1
03/19 07:35:04 PM: accumulation_steps = 1
03/19 07:35:04 PM: type = bert_adam
03/19 07:35:04 PM: parameter_groups = None
03/19 07:35:04 PM: Number of trainable parameters: 108706050
03/19 07:35:04 PM: infer_type_and_cast = True
03/19 07:35:04 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
03/19 07:35:04 PM: CURRENTLY DEFINED PARAMETERS: 
03/19 07:35:04 PM: lr = 0.005
03/19 07:35:04 PM: t_total = 1000
03/19 07:35:04 PM: warmup = 0.1
03/19 07:35:04 PM: type = reduce_on_plateau
03/19 07:35:04 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
03/19 07:35:04 PM: CURRENTLY DEFINED PARAMETERS: 
03/19 07:35:04 PM: mode = max
03/19 07:35:04 PM: factor = 0.5
03/19 07:35:04 PM: patience = 1
03/19 07:35:04 PM: threshold = 0.0001
03/19 07:35:04 PM: threshold_mode = abs
03/19 07:35:04 PM: verbose = True
03/19 07:35:04 PM: Starting training without restoring from a checkpoint.
03/19 07:35:04 PM: Training examples per task, before any subsampling: {'multirc': 27243}
03/19 07:35:04 PM: Beginning training with stopping criteria based on metric: multirc_avg
03/19 07:35:15 PM: Update 4: task multirc, steps since last val 4 (total steps = 4): ans_f1: 0.6667, qst_f1: 0.2581, em: 0.7097, avg: 0.6882, multirc_loss: 0.8448
03/19 07:35:26 PM: Update 9: task multirc, steps since last val 9 (total steps = 9): ans_f1: 0.6000, qst_f1: 0.2394, em: 0.6620, avg: 0.6310, multirc_loss: 1.1759
03/19 07:35:37 PM: Update 15: task multirc, steps since last val 15 (total steps = 15): ans_f1: 0.5657, qst_f1: 0.2288, em: 0.6356, avg: 0.6006, multirc_loss: 1.0262
03/19 07:35:47 PM: Update 20: task multirc, steps since last val 20 (total steps = 20): ans_f1: 0.5714, qst_f1: 0.2590, em: 0.5987, avg: 0.5851, multirc_loss: 1.1289
03/19 07:35:58 PM: Update 25: task multirc, steps since last val 25 (total steps = 25): ans_f1: 0.5122, qst_f1: 0.2107, em: 0.5959, avg: 0.5540, multirc_loss: 1.0856
03/19 07:36:10 PM: Update 30: task multirc, steps since last val 30 (total steps = 30): ans_f1: 0.5727, qst_f1: 0.2768, em: 0.5913, avg: 0.5820, multirc_loss: 1.0898
03/19 07:36:21 PM: Update 35: task multirc, steps since last val 35 (total steps = 35): ans_f1: 0.5525, qst_f1: 0.2619, em: 0.5789, avg: 0.5657, multirc_loss: 1.0530
03/19 07:36:33 PM: Update 40: task multirc, steps since last val 40 (total steps = 40): ans_f1: 0.5621, qst_f1: 0.2811, em: 0.5667, avg: 0.5644, multirc_loss: 1.0291
03/19 07:36:44 PM: Update 45: task multirc, steps since last val 45 (total steps = 45): ans_f1: 0.5496, qst_f1: 0.2834, em: 0.5359, avg: 0.5428, multirc_loss: 1.0241
03/19 07:36:55 PM: Update 50: task multirc, steps since last val 50 (total steps = 50): ans_f1: 0.5266, qst_f1: 0.2753, em: 0.5096, avg: 0.5181, multirc_loss: 1.0398
03/19 07:36:55 PM: ***** Step 50 / Validation 1 *****
03/19 07:36:55 PM: multirc: trained on 50 steps (50 batches) since val, 0.015 epochs
03/19 07:36:55 PM: Validating...
03/19 07:37:05 PM: Evaluate: task multirc, batch 66 (606): ans_f1: 0.6683, qst_f1: 0.6592, em: 0.0089, avg: 0.3386, multirc_loss: 0.6932
03/19 07:37:15 PM: Evaluate: task multirc, batch 126 (606): ans_f1: 0.6286, qst_f1: 0.6217, em: 0.0051, avg: 0.3168, multirc_loss: 0.6940
03/19 07:37:25 PM: Evaluate: task multirc, batch 189 (606): ans_f1: 0.6103, qst_f1: 0.5985, em: 0.0069, avg: 0.3086, multirc_loss: 0.6944
03/19 07:37:36 PM: Evaluate: task multirc, batch 251 (606): ans_f1: 0.5899, qst_f1: 0.5756, em: 0.0025, avg: 0.2962, multirc_loss: 0.6948
03/19 07:37:46 PM: Evaluate: task multirc, batch 312 (606): ans_f1: 0.5898, qst_f1: 0.5772, em: 0.0020, avg: 0.2959, multirc_loss: 0.6948
03/19 07:37:56 PM: Evaluate: task multirc, batch 371 (606): ans_f1: 0.5944, qst_f1: 0.5802, em: 0.0017, avg: 0.2980, multirc_loss: 0.6947
03/19 07:38:07 PM: Evaluate: task multirc, batch 429 (606): ans_f1: 0.6020, qst_f1: 0.5909, em: 0.0117, avg: 0.3069, multirc_loss: 0.6945
03/19 07:38:17 PM: Evaluate: task multirc, batch 478 (606): ans_f1: 0.6044, qst_f1: 0.5950, em: 0.0104, avg: 0.3074, multirc_loss: 0.6945
03/19 07:38:28 PM: Evaluate: task multirc, batch 524 (606): ans_f1: 0.6013, qst_f1: 0.5921, em: 0.0096, avg: 0.3054, multirc_loss: 0.6945
03/19 07:38:39 PM: Evaluate: task multirc, batch 579 (606): ans_f1: 0.5968, qst_f1: 0.5886, em: 0.0088, avg: 0.3028, multirc_loss: 0.6946
03/19 07:38:44 PM: Best result seen so far for multirc.
03/19 07:38:44 PM: Best result seen so far for micro.
03/19 07:38:44 PM: Best result seen so far for macro.
03/19 07:38:44 PM: Updating LR scheduler:
03/19 07:38:44 PM: 	Best result seen so far for macro_avg: 0.304
03/19 07:38:44 PM: 	# validation passes without improvement: 0
03/19 07:38:44 PM: multirc_loss: training: 1.039844 validation: 0.694574
03/19 07:38:44 PM: macro_avg: validation: 0.303923
03/19 07:38:44 PM: micro_avg: validation: 0.303923
03/19 07:38:44 PM: multirc_ans_f1: training: 0.526582 validation: 0.599451
03/19 07:38:44 PM: multirc_qst_f1: training: 0.275342 validation: 0.590961
03/19 07:38:44 PM: multirc_em: training: 0.509589 validation: 0.008395
03/19 07:38:44 PM: multirc_avg: training: 0.518086 validation: 0.303923
03/19 07:38:44 PM: Global learning rate: 0.005
03/19 07:38:44 PM: Saving checkpoints to: /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run4
03/19 07:38:49 PM: Update 52: task multirc, steps since last val 2 (total steps = 52): ans_f1: 0.3750, qst_f1: 0.1875, em: 0.3750, avg: 0.3750, multirc_loss: 0.8425
03/19 07:39:00 PM: Update 57: task multirc, steps since last val 7 (total steps = 57): ans_f1: 0.4211, qst_f1: 0.2099, em: 0.3889, avg: 0.4050, multirc_loss: 1.0838
03/19 07:39:11 PM: Update 62: task multirc, steps since last val 12 (total steps = 62): ans_f1: 0.4082, qst_f1: 0.2057, em: 0.3830, avg: 0.3956, multirc_loss: 1.2291
03/19 07:39:22 PM: Update 67: task multirc, steps since last val 17 (total steps = 67): ans_f1: 0.5063, qst_f1: 0.3003, em: 0.4198, avg: 0.4631, multirc_loss: 1.2111
03/19 07:39:34 PM: Update 72: task multirc, steps since last val 22 (total steps = 72): ans_f1: 0.4581, qst_f1: 0.2424, em: 0.4364, avg: 0.4472, multirc_loss: 1.1367
03/19 07:39:45 PM: Update 77: task multirc, steps since last val 27 (total steps = 77): ans_f1: 0.4762, qst_f1: 0.2657, em: 0.4307, avg: 0.4534, multirc_loss: 1.1389
03/19 07:39:58 PM: Update 82: task multirc, steps since last val 32 (total steps = 82): ans_f1: 0.4444, qst_f1: 0.2373, em: 0.4195, avg: 0.4320, multirc_loss: 1.1064
03/19 07:40:10 PM: Update 87: task multirc, steps since last val 37 (total steps = 87): ans_f1: 0.4214, qst_f1: 0.2088, em: 0.4396, avg: 0.4305, multirc_loss: 1.0684
03/19 07:40:20 PM: Update 92: task multirc, steps since last val 42 (total steps = 92): ans_f1: 0.4263, qst_f1: 0.2115, em: 0.4295, avg: 0.4279, multirc_loss: 1.0510
03/19 07:40:31 PM: Update 97: task multirc, steps since last val 47 (total steps = 97): ans_f1: 0.4463, qst_f1: 0.2263, em: 0.4379, avg: 0.4421, multirc_loss: 1.0283
03/19 07:40:37 PM: ***** Step 100 / Validation 2 *****
03/19 07:40:37 PM: multirc: trained on 50 steps (50 batches) since val, 0.015 epochs
03/19 07:40:37 PM: Validating...
03/19 07:40:41 PM: Evaluate: task multirc, batch 27 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 1.0218
03/19 07:40:51 PM: Evaluate: task multirc, batch 91 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.9699
03/19 07:41:01 PM: Evaluate: task multirc, batch 156 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.9030
03/19 07:41:12 PM: Evaluate: task multirc, batch 213 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0091, avg: 0.0045, multirc_loss: 0.8842
03/19 07:41:22 PM: Evaluate: task multirc, batch 267 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0047, avg: 0.0024, multirc_loss: 0.8828
03/19 07:41:32 PM: Evaluate: task multirc, batch 320 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0040, avg: 0.0020, multirc_loss: 0.8748
03/19 07:41:43 PM: Evaluate: task multirc, batch 367 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0052, avg: 0.0026, multirc_loss: 0.8857
03/19 07:41:54 PM: Evaluate: task multirc, batch 423 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0030, avg: 0.0015, multirc_loss: 0.8972
03/19 07:42:04 PM: Evaluate: task multirc, batch 474 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0052, avg: 0.0026, multirc_loss: 0.9004
03/19 07:42:15 PM: Evaluate: task multirc, batch 522 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0048, avg: 0.0024, multirc_loss: 0.8955
03/19 07:42:25 PM: Evaluate: task multirc, batch 575 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0044, avg: 0.0022, multirc_loss: 0.8895
03/19 07:42:31 PM: Updating LR scheduler:
03/19 07:42:31 PM: 	Best result seen so far for macro_avg: 0.304
03/19 07:42:31 PM: 	# validation passes without improvement: 1
03/19 07:42:31 PM: multirc_loss: training: 1.042495 validation: 0.892429
03/19 07:42:31 PM: macro_avg: validation: 0.001574
03/19 07:42:31 PM: micro_avg: validation: 0.001574
03/19 07:42:31 PM: multirc_ans_f1: training: 0.440318 validation: 0.000000
03/19 07:42:31 PM: multirc_qst_f1: training: 0.219249 validation: 0.000000
03/19 07:42:31 PM: multirc_em: training: 0.442254 validation: 0.003148
03/19 07:42:31 PM: multirc_avg: training: 0.441286 validation: 0.001574
03/19 07:42:31 PM: Global learning rate: 0.005
03/19 07:42:31 PM: Saving checkpoints to: /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run4
03/19 07:42:36 PM: Update 102: task multirc, steps since last val 2 (total steps = 102): ans_f1: 0.2353, qst_f1: 0.1250, em: 0.1875, avg: 0.2114, multirc_loss: 1.6730
03/19 07:42:47 PM: Update 107: task multirc, steps since last val 7 (total steps = 107): ans_f1: 0.3111, qst_f1: 0.1250, em: 0.4464, avg: 0.3788, multirc_loss: 1.0845
03/19 07:42:57 PM: Update 112: task multirc, steps since last val 12 (total steps = 112): ans_f1: 0.3855, qst_f1: 0.1702, em: 0.4681, avg: 0.4268, multirc_loss: 0.9843
03/19 07:43:08 PM: Update 117: task multirc, steps since last val 17 (total steps = 117): ans_f1: 0.4160, qst_f1: 0.1970, em: 0.4545, avg: 0.4353, multirc_loss: 0.9805
03/19 07:43:18 PM: Update 122: task multirc, steps since last val 22 (total steps = 122): ans_f1: 0.3974, qst_f1: 0.1765, em: 0.4765, avg: 0.4369, multirc_loss: 1.0707
03/19 07:43:29 PM: Update 127: task multirc, steps since last val 27 (total steps = 127): ans_f1: 0.3765, qst_f1: 0.1538, em: 0.5000, avg: 0.4382, multirc_loss: 1.1240
03/19 07:43:40 PM: Update 132: task multirc, steps since last val 32 (total steps = 132): ans_f1: 0.3756, qst_f1: 0.1495, em: 0.5021, avg: 0.4388, multirc_loss: 1.0743
03/19 07:43:50 PM: Update 137: task multirc, steps since last val 37 (total steps = 137): ans_f1: 0.3717, qst_f1: 0.1487, em: 0.5036, avg: 0.4376, multirc_loss: 1.0364
03/19 07:44:01 PM: Update 142: task multirc, steps since last val 42 (total steps = 142): ans_f1: 0.3586, qst_f1: 0.1412, em: 0.5032, avg: 0.4309, multirc_loss: 1.0897
03/19 07:44:11 PM: Update 147: task multirc, steps since last val 47 (total steps = 147): ans_f1: 0.3732, qst_f1: 0.1499, em: 0.5014, avg: 0.4373, multirc_loss: 1.0654
03/19 07:44:18 PM: ***** Step 150 / Validation 3 *****
03/19 07:44:18 PM: multirc: trained on 50 steps (50 batches) since val, 0.015 epochs
03/19 07:44:18 PM: Validating...
03/19 07:44:21 PM: Evaluate: task multirc, batch 23 (606): ans_f1: 0.6569, qst_f1: 0.6343, em: 0.0233, avg: 0.3401, multirc_loss: 0.9937
03/19 07:44:32 PM: Evaluate: task multirc, batch 88 (606): ans_f1: 0.6449, qst_f1: 0.6420, em: 0.0070, avg: 0.3259, multirc_loss: 1.0147
03/19 07:44:42 PM: Evaluate: task multirc, batch 156 (606): ans_f1: 0.6056, qst_f1: 0.5964, em: 0.0042, avg: 0.3049, multirc_loss: 1.0802
03/19 07:44:52 PM: Evaluate: task multirc, batch 217 (606): ans_f1: 0.5932, qst_f1: 0.5750, em: 0.0030, avg: 0.2981, multirc_loss: 1.1002
03/19 07:45:02 PM: Evaluate: task multirc, batch 271 (606): ans_f1: 0.5954, qst_f1: 0.5830, em: 0.0023, avg: 0.2989, multirc_loss: 1.0967
03/19 07:45:13 PM: Evaluate: task multirc, batch 325 (606): ans_f1: 0.5896, qst_f1: 0.5763, em: 0.0020, avg: 0.2958, multirc_loss: 1.1058
03/19 07:45:23 PM: Evaluate: task multirc, batch 380 (606): ans_f1: 0.5942, qst_f1: 0.5805, em: 0.0017, avg: 0.2980, multirc_loss: 1.0985
03/19 07:45:34 PM: Evaluate: task multirc, batch 442 (606): ans_f1: 0.6054, qst_f1: 0.5955, em: 0.0113, avg: 0.3083, multirc_loss: 1.0805
03/19 07:45:44 PM: Evaluate: task multirc, batch 508 (606): ans_f1: 0.6018, qst_f1: 0.5925, em: 0.0099, avg: 0.3058, multirc_loss: 1.0864
03/19 07:45:55 PM: Evaluate: task multirc, batch 574 (606): ans_f1: 0.5976, qst_f1: 0.5893, em: 0.0089, avg: 0.3033, multirc_loss: 1.0931
03/19 07:46:00 PM: Updating LR scheduler:
03/19 07:46:00 PM: 	Best result seen so far for macro_avg: 0.304
03/19 07:46:00 PM: 	# validation passes without improvement: 0
03/19 07:46:00 PM: multirc_loss: training: 1.072638 validation: 1.090162
03/19 07:46:00 PM: macro_avg: validation: 0.303923
03/19 07:46:00 PM: micro_avg: validation: 0.303923
03/19 07:46:00 PM: multirc_ans_f1: training: 0.383117 validation: 0.599451
03/19 07:46:00 PM: multirc_qst_f1: training: 0.157182 validation: 0.590961
03/19 07:46:00 PM: multirc_em: training: 0.498645 validation: 0.008395
03/19 07:46:00 PM: multirc_avg: training: 0.440881 validation: 0.303923
03/19 07:46:00 PM: Global learning rate: 0.0025
03/19 07:46:00 PM: Saving checkpoints to: /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run4
03/19 07:46:05 PM: Update 152: task multirc, steps since last val 2 (total steps = 152): ans_f1: 0.8571, qst_f1: 0.7500, em: 0.7500, avg: 0.8036, multirc_loss: 0.6489
03/19 07:46:16 PM: Update 157: task multirc, steps since last val 7 (total steps = 157): ans_f1: 0.5484, qst_f1: 0.3036, em: 0.5000, avg: 0.5242, multirc_loss: 0.9606
03/19 07:46:27 PM: Update 162: task multirc, steps since last val 12 (total steps = 162): ans_f1: 0.4421, qst_f1: 0.2234, em: 0.4362, avg: 0.4391, multirc_loss: 1.0822
03/19 07:46:38 PM: Update 167: task multirc, steps since last val 17 (total steps = 167): ans_f1: 0.4698, qst_f1: 0.2632, em: 0.4135, avg: 0.4417, multirc_loss: 1.1857
03/19 07:46:48 PM: Update 172: task multirc, steps since last val 22 (total steps = 172): ans_f1: 0.4217, qst_f1: 0.2027, em: 0.4444, avg: 0.4331, multirc_loss: 1.2076
03/19 07:46:59 PM: Update 177: task multirc, steps since last val 27 (total steps = 177): ans_f1: 0.4084, qst_f1: 0.1859, em: 0.4712, avg: 0.4398, multirc_loss: 1.1762
03/19 07:47:09 PM: Update 182: task multirc, steps since last val 32 (total steps = 182): ans_f1: 0.4105, qst_f1: 0.1923, em: 0.4564, avg: 0.4335, multirc_loss: 1.1510
03/19 07:47:19 PM: Update 187: task multirc, steps since last val 37 (total steps = 187): ans_f1: 0.3937, qst_f1: 0.1776, em: 0.4562, avg: 0.4250, multirc_loss: 1.1544
03/19 07:47:30 PM: Update 192: task multirc, steps since last val 42 (total steps = 192): ans_f1: 0.3772, qst_f1: 0.1661, em: 0.4563, avg: 0.4168, multirc_loss: 1.1138
03/19 07:47:40 PM: Update 197: task multirc, steps since last val 47 (total steps = 197): ans_f1: 0.3754, qst_f1: 0.1647, em: 0.4620, avg: 0.4187, multirc_loss: 1.0860
03/19 07:47:46 PM: ***** Step 200 / Validation 4 *****
03/19 07:47:46 PM: multirc: trained on 50 steps (50 batches) since val, 0.015 epochs
03/19 07:47:46 PM: Validating...
03/19 07:47:50 PM: Evaluate: task multirc, batch 30 (606): ans_f1: 0.6813, qst_f1: 0.6820, em: 0.0339, avg: 0.3576, multirc_loss: 1.2259
03/19 07:48:00 PM: Evaluate: task multirc, batch 103 (606): ans_f1: 0.6301, qst_f1: 0.6285, em: 0.0062, avg: 0.3182, multirc_loss: 1.3590
03/19 07:48:10 PM: Evaluate: task multirc, batch 175 (606): ans_f1: 0.6056, qst_f1: 0.5942, em: 0.0038, avg: 0.3047, multirc_loss: 1.4192
03/19 07:48:20 PM: Evaluate: task multirc, batch 244 (606): ans_f1: 0.5876, qst_f1: 0.5736, em: 0.0026, avg: 0.2951, multirc_loss: 1.4622
03/19 07:48:31 PM: Evaluate: task multirc, batch 308 (606): ans_f1: 0.5904, qst_f1: 0.5776, em: 0.0021, avg: 0.2962, multirc_loss: 1.4555
03/19 07:48:41 PM: Evaluate: task multirc, batch 375 (606): ans_f1: 0.5942, qst_f1: 0.5804, em: 0.0017, avg: 0.2980, multirc_loss: 1.4465
03/19 07:48:52 PM: Evaluate: task multirc, batch 438 (606): ans_f1: 0.6043, qst_f1: 0.5944, em: 0.0114, avg: 0.3078, multirc_loss: 1.4224
03/19 07:49:02 PM: Evaluate: task multirc, batch 501 (606): ans_f1: 0.6032, qst_f1: 0.5940, em: 0.0100, avg: 0.3066, multirc_loss: 1.4249
03/19 07:49:13 PM: Evaluate: task multirc, batch 561 (606): ans_f1: 0.6006, qst_f1: 0.5918, em: 0.0090, avg: 0.3048, multirc_loss: 1.4313
03/19 07:49:21 PM: Updating LR scheduler:
03/19 07:49:21 PM: 	Best result seen so far for macro_avg: 0.304
03/19 07:49:21 PM: 	# validation passes without improvement: 1
03/19 07:49:21 PM: multirc_loss: training: 1.091371 validation: 1.433961
03/19 07:49:21 PM: macro_avg: validation: 0.303923
03/19 07:49:21 PM: micro_avg: validation: 0.303923
03/19 07:49:21 PM: multirc_ans_f1: training: 0.383481 validation: 0.599451
03/19 07:49:21 PM: multirc_qst_f1: training: 0.174033 validation: 0.590961
03/19 07:49:21 PM: multirc_em: training: 0.447514 validation: 0.008395
03/19 07:49:21 PM: multirc_avg: training: 0.415497 validation: 0.303923
03/19 07:49:21 PM: Global learning rate: 0.0025
03/19 07:49:21 PM: Saving checkpoints to: /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run4
03/19 07:49:24 PM: Update 201: task multirc, steps since last val 1 (total steps = 201): ans_f1: 0.6667, qst_f1: 0.5000, em: 0.5000, avg: 0.5833, multirc_loss: 1.1920
03/19 07:49:34 PM: Update 206: task multirc, steps since last val 6 (total steps = 206): ans_f1: 0.4889, qst_f1: 0.2319, em: 0.5217, avg: 0.5053, multirc_loss: 1.0341
03/19 07:49:45 PM: Update 211: task multirc, steps since last val 11 (total steps = 211): ans_f1: 0.3099, qst_f1: 0.1255, em: 0.4353, avg: 0.3726, multirc_loss: 1.4050
03/19 07:49:55 PM: Update 216: task multirc, steps since last val 16 (total steps = 216): ans_f1: 0.4174, qst_f1: 0.1940, em: 0.4672, avg: 0.4423, multirc_loss: 1.2190
03/19 07:50:05 PM: Update 221: task multirc, steps since last val 21 (total steps = 221): ans_f1: 0.4444, qst_f1: 0.2158, em: 0.4808, avg: 0.4626, multirc_loss: 1.1060
03/19 07:50:16 PM: Update 226: task multirc, steps since last val 26 (total steps = 226): ans_f1: 0.3977, qst_f1: 0.1745, em: 0.4869, avg: 0.4423, multirc_loss: 1.1268
03/19 07:50:27 PM: Update 231: task multirc, steps since last val 31 (total steps = 231): ans_f1: 0.3810, qst_f1: 0.1740, em: 0.4558, avg: 0.4184, multirc_loss: 1.1403
03/19 07:50:38 PM: Update 236: task multirc, steps since last val 36 (total steps = 236): ans_f1: 0.4377, qst_f1: 0.2148, em: 0.4601, avg: 0.4489, multirc_loss: 1.1147
03/19 07:50:50 PM: Update 241: task multirc, steps since last val 41 (total steps = 241): ans_f1: 0.4143, qst_f1: 0.1909, em: 0.4730, avg: 0.4436, multirc_loss: 1.1117
03/19 07:51:01 PM: Update 246: task multirc, steps since last val 46 (total steps = 246): ans_f1: 0.4089, qst_f1: 0.1894, em: 0.4727, avg: 0.4408, multirc_loss: 1.1191
03/19 07:51:10 PM: ***** Step 250 / Validation 5 *****
03/19 07:51:11 PM: multirc: trained on 50 steps (50 batches) since val, 0.015 epochs
03/19 07:51:11 PM: Validating...
03/19 07:51:11 PM: Evaluate: task multirc, batch 2 (606): ans_f1: 0.5455, qst_f1: 0.5345, em: 0.0000, avg: 0.2727, multirc_loss: 0.9961
03/19 07:51:21 PM: Evaluate: task multirc, batch 66 (606): ans_f1: 0.6683, qst_f1: 0.6592, em: 0.0089, avg: 0.3386, multirc_loss: 0.8494
03/19 07:51:31 PM: Evaluate: task multirc, batch 124 (606): ans_f1: 0.6298, qst_f1: 0.6230, em: 0.0052, avg: 0.3175, multirc_loss: 0.8982
03/19 07:51:42 PM: Evaluate: task multirc, batch 180 (606): ans_f1: 0.6087, qst_f1: 0.5971, em: 0.0037, avg: 0.3062, multirc_loss: 0.9239
03/19 07:51:52 PM: Evaluate: task multirc, batch 234 (606): ans_f1: 0.5909, qst_f1: 0.5742, em: 0.0027, avg: 0.2968, multirc_loss: 0.9448
03/19 07:52:02 PM: Evaluate: task multirc, batch 286 (606): ans_f1: 0.5942, qst_f1: 0.5814, em: 0.0022, avg: 0.2982, multirc_loss: 0.9410
03/19 07:52:13 PM: Evaluate: task multirc, batch 336 (606): ans_f1: 0.5916, qst_f1: 0.5786, em: 0.0019, avg: 0.2967, multirc_loss: 0.9441
03/19 07:52:23 PM: Evaluate: task multirc, batch 387 (606): ans_f1: 0.5959, qst_f1: 0.5827, em: 0.0050, avg: 0.3005, multirc_loss: 0.9390
03/19 07:52:34 PM: Evaluate: task multirc, batch 443 (606): ans_f1: 0.6058, qst_f1: 0.5963, em: 0.0126, avg: 0.3092, multirc_loss: 0.9273
03/19 07:52:44 PM: Evaluate: task multirc, batch 504 (606): ans_f1: 0.6024, qst_f1: 0.5932, em: 0.0100, avg: 0.3062, multirc_loss: 0.9313
03/19 07:52:55 PM: Evaluate: task multirc, batch 568 (606): ans_f1: 0.5984, qst_f1: 0.5904, em: 0.0090, avg: 0.3037, multirc_loss: 0.9361
03/19 07:53:01 PM: Updating LR scheduler:
03/19 07:53:01 PM: 	Best result seen so far for macro_avg: 0.304
03/19 07:53:01 PM: 	# validation passes without improvement: 0
03/19 07:53:01 PM: multirc_loss: training: 1.136093 validation: 0.934822
03/19 07:53:01 PM: macro_avg: validation: 0.303923
03/19 07:53:01 PM: micro_avg: validation: 0.303923
03/19 07:53:01 PM: multirc_ans_f1: training: 0.414773 validation: 0.599451
03/19 07:53:01 PM: multirc_qst_f1: training: 0.198481 validation: 0.590961
03/19 07:53:01 PM: multirc_em: training: 0.458689 validation: 0.008395
03/19 07:53:01 PM: multirc_avg: training: 0.436731 validation: 0.303923
03/19 07:53:01 PM: Global learning rate: 0.00125
03/19 07:53:01 PM: Saving checkpoints to: /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run4
03/19 07:53:06 PM: Update 252: task multirc, steps since last val 2 (total steps = 252): ans_f1: 0.5263, qst_f1: 0.3125, em: 0.4375, avg: 0.4819, multirc_loss: 0.7399
03/19 07:53:18 PM: Update 258: task multirc, steps since last val 8 (total steps = 258): ans_f1: 0.2000, qst_f1: 0.0833, em: 0.3833, avg: 0.2917, multirc_loss: 1.1262
03/19 07:53:28 PM: Update 263: task multirc, steps since last val 13 (total steps = 263): ans_f1: 0.1690, qst_f1: 0.0606, em: 0.4343, avg: 0.3017, multirc_loss: 1.0744
03/19 07:53:39 PM: Update 268: task multirc, steps since last val 18 (total steps = 268): ans_f1: 0.3130, qst_f1: 0.1324, em: 0.4632, avg: 0.3881, multirc_loss: 1.0138
03/19 07:53:50 PM: Update 273: task multirc, steps since last val 23 (total steps = 273): ans_f1: 0.4167, qst_f1: 0.2039, em: 0.4706, avg: 0.4436, multirc_loss: 0.9971
03/19 07:54:01 PM: Update 278: task multirc, steps since last val 28 (total steps = 278): ans_f1: 0.4631, qst_f1: 0.2238, em: 0.5169, avg: 0.4900, multirc_loss: 0.9530
03/19 07:54:12 PM: Update 283: task multirc, steps since last val 33 (total steps = 283): ans_f1: 0.4502, qst_f1: 0.2077, em: 0.5164, avg: 0.4833, multirc_loss: 0.9223
03/19 07:54:23 PM: Update 288: task multirc, steps since last val 38 (total steps = 288): ans_f1: 0.4723, qst_f1: 0.2258, em: 0.5181, avg: 0.4952, multirc_loss: 0.8993
03/19 07:54:35 PM: Update 293: task multirc, steps since last val 43 (total steps = 293): ans_f1: 0.4720, qst_f1: 0.2369, em: 0.4887, avg: 0.4804, multirc_loss: 0.9088
03/19 07:54:46 PM: Update 298: task multirc, steps since last val 48 (total steps = 298): ans_f1: 0.4765, qst_f1: 0.2367, em: 0.4899, avg: 0.4832, multirc_loss: 0.9090
03/19 07:54:50 PM: ***** Step 300 / Validation 6 *****
03/19 07:54:51 PM: multirc: trained on 50 steps (50 batches) since val, 0.015 epochs
03/19 07:54:51 PM: Validating...
03/19 07:54:56 PM: Evaluate: task multirc, batch 37 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7521
03/19 07:55:07 PM: Evaluate: task multirc, batch 92 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7374
03/19 07:55:17 PM: Evaluate: task multirc, batch 140 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.7151
03/19 07:55:27 PM: Evaluate: task multirc, batch 195 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0033, avg: 0.0017, multirc_loss: 0.7125
03/19 07:55:37 PM: Evaluate: task multirc, batch 254 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0050, avg: 0.0025, multirc_loss: 0.6980
03/19 07:55:48 PM: Evaluate: task multirc, batch 314 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0061, avg: 0.0031, multirc_loss: 0.6972
03/19 07:55:58 PM: Evaluate: task multirc, batch 372 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0035, avg: 0.0017, multirc_loss: 0.7009
03/19 07:56:09 PM: Evaluate: task multirc, batch 432 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0029, avg: 0.0014, multirc_loss: 0.7077
03/19 07:56:19 PM: Evaluate: task multirc, batch 490 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0038, avg: 0.0019, multirc_loss: 0.7074
03/19 07:56:29 PM: Evaluate: task multirc, batch 546 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0034, avg: 0.0017, multirc_loss: 0.7074
03/19 07:56:40 PM: Evaluate: task multirc, batch 605 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0032, avg: 0.0016, multirc_loss: 0.7046
03/19 07:56:41 PM: Updating LR scheduler:
03/19 07:56:41 PM: 	Best result seen so far for macro_avg: 0.304
03/19 07:56:41 PM: 	# validation passes without improvement: 1
03/19 07:56:41 PM: multirc_loss: training: 0.917917 validation: 0.704990
03/19 07:56:41 PM: macro_avg: validation: 0.001574
03/19 07:56:41 PM: micro_avg: validation: 0.001574
03/19 07:56:41 PM: multirc_ans_f1: training: 0.463612 validation: 0.000000
03/19 07:56:41 PM: multirc_qst_f1: training: 0.229108 validation: 0.000000
03/19 07:56:41 PM: multirc_em: training: 0.481690 validation: 0.003148
03/19 07:56:41 PM: multirc_avg: training: 0.472651 validation: 0.001574
03/19 07:56:41 PM: Global learning rate: 0.00125
03/19 07:56:41 PM: Saving checkpoints to: /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run4
03/19 07:56:51 PM: Update 304: task multirc, steps since last val 4 (total steps = 304): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.5625, avg: 0.2812, multirc_loss: 0.8238
03/19 07:57:01 PM: Update 309: task multirc, steps since last val 9 (total steps = 309): ans_f1: 0.0645, qst_f1: 0.0141, em: 0.5915, avg: 0.3280, multirc_loss: 0.7599
03/19 07:57:12 PM: Update 314: task multirc, steps since last val 14 (total steps = 314): ans_f1: 0.2571, qst_f1: 0.0818, em: 0.5273, avg: 0.3922, multirc_loss: 0.7907
03/19 07:57:23 PM: Update 319: task multirc, steps since last val 19 (total steps = 319): ans_f1: 0.3967, qst_f1: 0.1610, em: 0.5034, avg: 0.4500, multirc_loss: 0.7824
03/19 07:57:34 PM: Update 324: task multirc, steps since last val 24 (total steps = 324): ans_f1: 0.3758, qst_f1: 0.1676, em: 0.4365, avg: 0.4061, multirc_loss: 0.8411
03/19 07:57:45 PM: Update 329: task multirc, steps since last val 29 (total steps = 329): ans_f1: 0.3981, qst_f1: 0.1887, em: 0.4247, avg: 0.4114, multirc_loss: 0.8413
03/19 07:57:55 PM: Update 334: task multirc, steps since last val 34 (total steps = 334): ans_f1: 0.3723, qst_f1: 0.1660, em: 0.4387, avg: 0.4055, multirc_loss: 0.8371
03/19 07:58:06 PM: Update 339: task multirc, steps since last val 39 (total steps = 339): ans_f1: 0.3411, qst_f1: 0.1492, em: 0.4231, avg: 0.3821, multirc_loss: 0.8741
03/19 07:58:17 PM: Update 344: task multirc, steps since last val 44 (total steps = 344): ans_f1: 0.3368, qst_f1: 0.1438, em: 0.4313, avg: 0.3840, multirc_loss: 0.8604
03/19 07:58:28 PM: Update 349: task multirc, steps since last val 49 (total steps = 349): ans_f1: 0.3386, qst_f1: 0.1486, em: 0.4229, avg: 0.3807, multirc_loss: 0.8511
03/19 07:58:30 PM: ***** Step 350 / Validation 7 *****
03/19 07:58:30 PM: multirc: trained on 50 steps (50 batches) since val, 0.015 epochs
03/19 07:58:30 PM: Validating...
03/19 07:58:38 PM: Evaluate: task multirc, batch 52 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.6942
03/19 07:58:48 PM: Evaluate: task multirc, batch 115 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.6914
03/19 07:58:59 PM: Evaluate: task multirc, batch 173 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0000, avg: 0.0000, multirc_loss: 0.6896
03/19 07:59:09 PM: Evaluate: task multirc, batch 236 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0054, avg: 0.0027, multirc_loss: 0.6888
03/19 07:59:19 PM: Evaluate: task multirc, batch 297 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0043, avg: 0.0021, multirc_loss: 0.6888
03/19 07:59:30 PM: Evaluate: task multirc, batch 357 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0036, avg: 0.0018, multirc_loss: 0.6890
03/19 07:59:40 PM: Evaluate: task multirc, batch 421 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0030, avg: 0.0015, multirc_loss: 0.6894
03/19 07:59:51 PM: Evaluate: task multirc, batch 487 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0038, avg: 0.0019, multirc_loss: 0.6895
03/19 08:00:01 PM: Evaluate: task multirc, batch 552 (606): ans_f1: 0.0000, qst_f1: 0.0000, em: 0.0034, avg: 0.0017, multirc_loss: 0.6894
03/19 08:00:10 PM: Updating LR scheduler:
03/19 08:00:10 PM: 	Best result seen so far for macro_avg: 0.304
03/19 08:00:10 PM: 	# validation passes without improvement: 0
03/19 08:00:10 PM: Ran out of early stopping patience. Stopping training.
03/19 08:00:10 PM: multirc_loss: training: 0.861539 validation: 0.689242
03/19 08:00:10 PM: macro_avg: validation: 0.001574
03/19 08:00:10 PM: micro_avg: validation: 0.001574
03/19 08:00:10 PM: multirc_ans_f1: training: 0.335366 validation: 0.000000
03/19 08:00:10 PM: multirc_qst_f1: training: 0.148045 validation: 0.000000
03/19 08:00:10 PM: multirc_em: training: 0.416201 validation: 0.003148
03/19 08:00:10 PM: multirc_avg: training: 0.375783 validation: 0.001574
03/19 08:00:10 PM: Global learning rate: 0.000625
03/19 08:00:10 PM: Saving checkpoints to: /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run4
03/19 08:00:11 PM: Stopped training after 7 validation checks
03/19 08:00:11 PM: Trained multirc for 350 steps or 0.103 epochs
03/19 08:00:11 PM: ***** VALIDATION RESULTS *****
03/19 08:00:11 PM: multirc_avg (for best val pass 1): multirc_loss: 0.69457, macro_avg: 0.30392, micro_avg: 0.30392, multirc_ans_f1: 0.59945, multirc_qst_f1: 0.59096, multirc_em: 0.00839, multirc_avg: 0.30392
03/19 08:00:11 PM: micro_avg (for best val pass 1): multirc_loss: 0.69457, macro_avg: 0.30392, micro_avg: 0.30392, multirc_ans_f1: 0.59945, multirc_qst_f1: 0.59096, multirc_em: 0.00839, multirc_avg: 0.30392
03/19 08:00:11 PM: macro_avg (for best val pass 1): multirc_loss: 0.69457, macro_avg: 0.30392, micro_avg: 0.30392, multirc_ans_f1: 0.59945, multirc_qst_f1: 0.59096, multirc_em: 0.00839, multirc_avg: 0.30392
03/19 08:00:11 PM: Evaluating...
03/19 08:00:11 PM: Loaded model state from /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run4/model_state_pretrain_val_1.best.th
03/19 08:00:11 PM: Evaluating on: multirc, split: val
03/19 08:00:42 PM: 	Task multirc: batch 192
03/19 08:01:12 PM: 	Task multirc: batch 387
03/19 08:01:42 PM: 	Task multirc: batch 576
03/19 08:01:47 PM: Task 'multirc': sorting predictions by 'idx'
03/19 08:01:47 PM: Finished evaluating on: multirc
03/19 08:01:47 PM: Writing results for split 'val' to /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/results.tsv
03/19 08:01:47 PM: micro_avg: 0.304, macro_avg: 0.304, multirc_ans_f1: 0.599, multirc_qst_f1: 0.591, multirc_em: 0.008, multirc_avg: 0.304
03/19 08:01:47 PM: Done!
03/19 09:05:19 PM: Git branch: develop
03/19 09:05:19 PM: Git SHA: 23cd1ee178a5b6267ac9d6fd5cba8f1d5ae0c538
03/19 09:05:20 PM: Parsed args: 
{
  "batch_size": 8,
  "d_word": 50,
  "do_target_task_training": 0,
  "exp_dir": "/Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/",
  "exp_name": "mutlirc_bert_cased_exp",
  "input_module": "bert-base-cased",
  "load_model": 0,
  "local_log_path": "/Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run4/log.log",
  "lr": 0.05,
  "max_epochs": 10,
  "max_seq_len": 10,
  "max_vals": 20,
  "max_word_v_size": 1000,
  "optimizer": "bert_adam",
  "pair_attn": 0,
  "pretrain_tasks": "multirc",
  "random_seed": 22,
  "remote_log_name": "mutlirc_bert_cased_exp__mutlirc_bert_cased_run4",
  "run_dir": "/Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run4",
  "run_name": "mutlirc_bert_cased_run4",
  "sent_enc": "bow",
  "skip_embs": 0,
  "target_tasks": "multirc",
  "target_train_max_vals": 10,
  "target_train_val_interval": 10,
  "transfer_paradigm": "finetune",
  "val_interval": 50
}
03/19 09:05:20 PM: Saved config to /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run4/params.conf
03/19 09:05:20 PM: Using random seed 22
03/19 09:05:20 PM: Loading tasks...
03/19 09:05:20 PM: Writing pre-preprocessed tasks to /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/
03/19 09:05:20 PM: 	Loaded existing task multirc
03/19 09:05:20 PM: 	Task 'multirc': |train|=27243 |val|=4848 |test|=9693
03/19 09:05:20 PM: 	Finished loading tasks: multirc.
03/19 09:05:20 PM: Loading token dictionary from /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/vocab.
03/19 09:05:20 PM: 	Loaded vocab from /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/vocab
03/19 09:05:20 PM: 	Vocab namespace chars: size 100
03/19 09:05:20 PM: 	Vocab namespace bert_cased: size 28998
03/19 09:05:20 PM: 	Vocab namespace tokens: size 1004
03/19 09:05:20 PM: 	Finished building vocab.
03/19 09:05:20 PM: 	Task 'multirc', split 'train': Found preprocessed copy in /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/preproc/multirc__train_data
03/19 09:05:20 PM: 	Task 'multirc', split 'val': Found preprocessed copy in /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/preproc/multirc__val_data
03/19 09:05:20 PM: 	Task 'multirc', split 'test': Found preprocessed copy in /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/preproc/multirc__test_data
03/19 09:05:20 PM: 	Finished indexing tasks
03/19 09:05:20 PM: 	Creating trimmed pretraining-only version of multirc train.
03/19 09:05:20 PM: 	Creating trimmed target-only version of multirc train.
03/19 09:05:20 PM: 	  Training on multirc
03/19 09:05:20 PM: 	  Evaluating on multirc
03/19 09:05:20 PM: 	Finished loading tasks in 0.091s
03/19 09:05:20 PM: 	 Tasks: ['multirc']
03/19 09:05:20 PM: Building model...
03/19 09:05:20 PM: Using BERT model (bert-base-cased).
03/19 09:05:20 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/transformers_cache/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.3d5adf10d3445c36ce131f4c6416aa62e9b58e1af56b97664773f4858a46286e
03/19 09:05:20 PM: Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "output_past": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 28996
}

03/19 09:05:20 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/transformers_cache/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
03/19 09:05:22 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/transformers_cache/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
03/19 09:05:22 PM: Initializing parameters
03/19 09:05:22 PM: Done initializing parameters; the following parameters are using their default initialization from their code
03/19 09:05:22 PM:    _text_field_embedder.model.embeddings.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.embeddings.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.embeddings.position_embeddings.weight
03/19 09:05:22 PM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
03/19 09:05:22 PM:    _text_field_embedder.model.embeddings.word_embeddings.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
03/19 09:05:22 PM:    _text_field_embedder.model.pooler.dense.bias
03/19 09:05:22 PM:    _text_field_embedder.model.pooler.dense.weight
03/19 09:05:22 PM: 	Task 'multirc' params: {
  "cls_type": "mlp",
  "d_hid": 512,
  "pool_type": "max",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.2,
  "cls_loss_fn": "softmax",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "multirc"
}
03/19 09:05:22 PM: Model specification:
03/19 09:05:22 PM: MultiTaskModel(
  (sent_encoder): BoWSentEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (multirc_mdl): SingleClassifier(
    (pooler): Pooler()
    (classifier): Classifier(
      (classifier): Sequential(
        (0): Linear(in_features=768, out_features=512, bias=True)
        (1): Tanh()
        (2): LayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (3): Dropout(p=0.2)
        (4): Linear(in_features=512, out_features=2, bias=True)
      )
    )
  )
)
03/19 09:05:22 PM: Model parameters:
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Trainable parameter, count 22268928 with torch.Size([28996, 768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Trainable parameter, count 393216 with torch.Size([512, 768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Trainable parameter, count 1536 with torch.Size([2, 768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 09:05:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
03/19 09:05:23 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Trainable parameter, count 768 with torch.Size([768])
03/19 09:05:23 PM: 	multirc_mdl.classifier.classifier.0.weight: Trainable parameter, count 393216 with torch.Size([512, 768])
03/19 09:05:23 PM: 	multirc_mdl.classifier.classifier.0.bias: Trainable parameter, count 512 with torch.Size([512])
03/19 09:05:23 PM: 	multirc_mdl.classifier.classifier.2.weight: Trainable parameter, count 512 with torch.Size([512])
03/19 09:05:23 PM: 	multirc_mdl.classifier.classifier.2.bias: Trainable parameter, count 512 with torch.Size([512])
03/19 09:05:23 PM: 	multirc_mdl.classifier.classifier.4.weight: Trainable parameter, count 1024 with torch.Size([2, 512])
03/19 09:05:23 PM: 	multirc_mdl.classifier.classifier.4.bias: Trainable parameter, count 2 with torch.Size([2])
03/19 09:05:23 PM: Total number of parameters: 108706050 (1.08706e+08)
03/19 09:05:23 PM: Number of trainable parameters: 108706050 (1.08706e+08)
03/19 09:05:23 PM: Finished building model in 2.405s
03/19 09:05:23 PM: Will run the following steps for this experiment:
Training model on tasks: multirc 
Evaluating model on tasks: multirc 

03/19 09:05:23 PM: Training...
03/19 09:05:23 PM: patience = 5
03/19 09:05:23 PM: val_interval = 50
03/19 09:05:23 PM: max_vals = 20
03/19 09:05:23 PM: cuda_device = -1
03/19 09:05:23 PM: grad_norm = 5.0
03/19 09:05:23 PM: grad_clipping = None
03/19 09:05:23 PM: lr_decay = 0.99
03/19 09:05:23 PM: min_lr = 1e-06
03/19 09:05:23 PM: keep_all_checkpoints = 0
03/19 09:05:23 PM: val_data_limit = 5000
03/19 09:05:23 PM: max_epochs = 10
03/19 09:05:23 PM: dec_val_scale = 250
03/19 09:05:23 PM: training_data_fraction = 1
03/19 09:05:23 PM: accumulation_steps = 1
03/19 09:05:23 PM: type = bert_adam
03/19 09:05:23 PM: parameter_groups = None
03/19 09:05:23 PM: Number of trainable parameters: 108706050
03/19 09:05:23 PM: infer_type_and_cast = True
03/19 09:05:23 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
03/19 09:05:23 PM: CURRENTLY DEFINED PARAMETERS: 
03/19 09:05:23 PM: lr = 0.05
03/19 09:05:23 PM: t_total = 1000
03/19 09:05:23 PM: warmup = 0.1
03/19 09:05:23 PM: type = reduce_on_plateau
03/19 09:05:23 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
03/19 09:05:23 PM: CURRENTLY DEFINED PARAMETERS: 
03/19 09:05:23 PM: mode = max
03/19 09:05:23 PM: factor = 0.5
03/19 09:05:23 PM: patience = 1
03/19 09:05:23 PM: threshold = 0.0001
03/19 09:05:23 PM: threshold_mode = abs
03/19 09:05:23 PM: verbose = True
03/19 09:05:23 PM: Starting training without restoring from a checkpoint.
03/19 09:05:23 PM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/Users/hpaila/Projects/NLP/multi_rc/baseline/jiant/__main__.py", line 588, in main
    phase="pretrain",
  File "/Users/hpaila/Projects/NLP/multi_rc/baseline/jiant/trainer.py", line 526, in train
    check_for_previous_checkpoints(self._serialization_dir, tasks, phase, load_model)
  File "/Users/hpaila/Projects/NLP/multi_rc/baseline/jiant/utils/utils.py", line 154, in check_for_previous_checkpoints
    % serialization_dir,
  File "/Users/hpaila/Projects/NLP/multi_rc/baseline/jiant/utils/utils.py", line 484, in assert_for_log
    assert condition, error_message
AssertionError: There are existing checkpoints in /Users/hpaila/Projects/NLP/multi_rc/baseline/output/mutlirc_bert_cased_exp/mutlirc_bert_cased_run4 which will be overwritten. If you are restoring from a run, or would like to train from an existing checkpoint, Use load_model = 1 to load the checkpoints instead. If you don't want them, delete them or change your experiment name.
