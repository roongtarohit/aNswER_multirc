// https://jiant.info/documentation#/

include "defaults.conf"  // relative path to this file

// write to local storage by default for this demo
exp_name = jiant-demo
run_name = mtl-sst-mrpc

//The main differences between an experiment and a run is that all runs in an experiment will have the same preprocessing (which may include tokenization differences), while runs his a specific experiment (which may differ from other runs by learning rate or type of sentence encoder, for example, your run name could be rnn_encoder for a run with a biLSTM sentence encoder).

cuda = -1
random_seed = 42

load_model = 0
reload_tasks = 0
reload_indexing = 0
reload_vocab = 0

pretrain_tasks = "multirc" //string of tasks. Our training phase handles the phase differently
target_tasks = "multirc" //tasks you want to fine-tune and evaluate on
classifier = mlp
classifier_hid_dim = 32
max_seq_len = 10
max_word_v_size = 1000
pair_attn = 0

input_module = scratch //specifying the type of (contextualized) word embedding you want to use
d_word = 50


sent_enc = rnn  //  If you want to train a new sentence encoder (rather than using a loaded one like BERT), specify it here [Read more in default.conf]
    // LSTM uses RNN as the encoder?
skip_embs = 0

batch_size = 8

val_interval = 50 //interval (in steps) at which you want to evaluate your model on the validation set during pretraining. A step is a batch update.
max_vals = 10
target_train_val_interval = 10
target_train_max_vals = 10

// Use += to inherit from any previously-defined task tuples.
sts-b += {
    classifier_hid_dim = 512
    pair_attn = 0
    max_vals = 16
    val_interval = 10
}


// There are two sets of losses and scores outputted for the two tasks. This is because we're doing multitask learning in this phase. Then, after the pretraining phase, during target task training, you will see updates for only one task at a time, and after each validation, only scores for that one task.

// After running this experiment, you should have in your run directory: a checkpoint of the best model state (based on your scores) for both pretraining and target task training phase. The target task checkpoints will be under a subdirectory of the target tasks in the run directory, including checkpoints for metrics, model states, training states, and task states at each epoch.
//a log.log file which contains all the logs
//params.conf (a saved version of the parameters used)
//written predictions for test for each of the target trained tasks (with file names {task_name}-test.tsv)
//a saved checkpoint of your best validation metric.
//A tensorboard directory that logs the runs from train and val for all task-specific metrics. Note that right now we do not support logging for macro and micro averages.
//Additionally, the validation scores will be written in results.tsv in your experiment directory with the name of the run it belongs to.


